{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDYnDRjPfNF_"
   },
   "source": [
    "# DL Project 2023/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ll5uAwzhfYHn"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Description of the method choosen and the work done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision matplotlib tqdm Pillow numpy --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19732,
     "status": "ok",
     "timestamp": 1715970600487,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "Lw7k2mxRfE1D"
   },
   "outputs": [],
   "source": [
    "# Import PyTorch and related modules\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Import torchvision and related modules\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import multiprocessing\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37897,
     "status": "ok",
     "timestamp": 1715970642796,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "qQnIh3lo3VAS",
    "outputId": "94b3fb3e-e93d-4bf2-eceb-79b231353554"
   },
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "    tar_file = \"/content/drive/MyDrive/DL_project/imagenet-a.tar\"\n",
    "else:\n",
    "    # Set the path for Jupyter \n",
    "    tar_file = \"./imagenet-a.tar\"\n",
    "\n",
    "data_folder = \"imagenet-a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqX-jwMHgZ3G"
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21703,
     "status": "ok",
     "timestamp": 1715970667457,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "4h7Y7SSrgc7y",
    "outputId": "bd874e65-9065-46ec-947e-8a4ae09e067e"
   },
   "outputs": [],
   "source": [
    "# function to untar the dataset and store it in a new folder\n",
    "def extract_dataset(compress_file, destination_folder):\n",
    "  # function to change dir names to their words description\n",
    "  def change_folders_names(readme_file, dataset_root):\n",
    "    with open(readme_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            # Match lines containing WordNet IDs and descriptions\n",
    "            match = re.match(r'n\\d+ (.+)', line)\n",
    "            if match:\n",
    "                # Split the line into WordNet ID and description\n",
    "                parts = match.group(0).split()\n",
    "                wordnet_id = parts[0]\n",
    "                description = ' '.join(parts[1:])\n",
    "                os.rename(os.path.join(dataset_root, wordnet_id),\n",
    "                            os.path.join(dataset_root, description))\n",
    "\n",
    "  if not os.path.exists(compress_file):\n",
    "    print(\"Compress file doesn't exist.\")\n",
    "    return\n",
    "\n",
    "  if os.path.exists(destination_folder):\n",
    "    # remove the folder if already exists one\n",
    "    shutil.rmtree(destination_folder)\n",
    "\n",
    "  # extract content from the .tar file\n",
    "  with tarfile.open(compress_file, 'r') as tar_ref:\n",
    "    tar_ref.extractall(\"./\")\n",
    "  print(\"All the data is extracted.\")\n",
    "\n",
    "  change_folders_names(destination_folder+\"/README.txt\", destination_folder)\n",
    "\n",
    "extract_dataset(tar_file, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1715970670636,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "rzBAWU06L_Mm",
    "outputId": "2a005eca-33f2-45bb-ea03-a7427ee7fa99"
   },
   "outputs": [],
   "source": [
    "ids_list = os.listdir(data_folder)\n",
    "len(ids_list) # 200 folders + 1 readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, dataset_path, transform):\n",
    "    # Load the entire dataset\n",
    "    data = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "    \n",
    "    # Get the class labels\n",
    "    class_labels = data.classes\n",
    "    print(f\"The dataset contains {len(data)} images.\")\n",
    "    print(f\"The dataset contains {len(class_labels)} labels.\")\n",
    "    \n",
    "    # Create a subset with only the first 1000 images\n",
    "    subset_indices = list(range(100))  # Indices of the first 1000 images\n",
    "    data_subset = torch.utils.data.Subset(data, subset_indices)\n",
    "    \n",
    "    # Create a DataLoader for the subset\n",
    "    test_loader = torch.utils.data.DataLoader(data_subset, batch_size=batch_size, shuffle=False, num_workers=multiprocessing.cpu_count())\n",
    "    \n",
    "    return test_loader, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1715970673171,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "eul04CxP3VaH"
   },
   "outputs": [],
   "source": [
    "# function that returns a DataLoader for the dataset\n",
    "def get_data(batch_size, dataset_path, transform):\n",
    "\n",
    "  data = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "  class_labels = data.classes\n",
    "  print(f\"The dataset contains {len(data)} images.\")\n",
    "  print(f\"The dataset contains {len(class_labels)} labels.\")\n",
    "\n",
    "  test_loader = torch.utils.data.DataLoader(data, batch_size, shuffle=False, num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "  return test_loader, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1715970676875,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "HHAElKCP7mMv"
   },
   "outputs": [],
   "source": [
    "# function to display images from the DataLoader\n",
    "def show_images(dataloader, num_images=5):\n",
    "  # get a batch of data\n",
    "  data_iter = iter(dataloader)\n",
    "  images, labels = next(data_iter)\n",
    "\n",
    "  # convert images to numpy array\n",
    "  images = images.numpy()\n",
    "\n",
    "  # display images\n",
    "  fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "  for i in range(num_images):\n",
    "      image = np.transpose(images[i], (1, 2, 0))  # move channels in last position\n",
    "      image = np.clip(image, 0, 1)\n",
    "      axes[i].imshow(image)\n",
    "      axes[i].axis('off')\n",
    "      axes[i].set_title(dataloader.dataset.classes[labels[i]])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class blocked_grad(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, mask):\n",
    "        ctx.save_for_backward(x, mask)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, mask = ctx.saved_tensors\n",
    "        return grad_output * mask, mask * 0.0\n",
    "\n",
    "class GroupLinearLayer(nn.Module):\n",
    "    def __init__(self, din, dout, num_blocks):\n",
    "        super(GroupLinearLayer, self).__init__()\n",
    "        self.w = nn.Parameter(0.01 * torch.randn(num_blocks, din, dout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = torch.bmm(x, self.w)\n",
    "        return x.permute(1, 0, 2)\n",
    "\n",
    "class GroupLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    GroupLSTMCell can compute the operation of N LSTM Cells at once.\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_size, hidden_size, num_lstms):\n",
    "        super().__init__()\n",
    "        self.inp_size = inp_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = GroupLinearLayer(inp_size, 4 * hidden_size, num_lstms)\n",
    "        self.h2h = GroupLinearLayer(hidden_size, 4 * hidden_size, num_lstms)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, hid_state):\n",
    "        \"\"\"\n",
    "        input: x (batch_size, num_lstms, input_size)\n",
    "               hid_state (tuple of length 2 with each element of size (batch_size, num_lstms, hidden_state))\n",
    "        output: h (batch_size, num_lstms, hidden_state)\n",
    "                c ((batch_size, num_lstms, hidden_state))\n",
    "        \"\"\"\n",
    "        h, c = hid_state\n",
    "        preact = self.i2h(x) + self.h2h(h)\n",
    "        gates = preact[:, :, :3 * self.hidden_size].sigmoid()\n",
    "        g_t = preact[:, :, 3 * self.hidden_size:].tanh()\n",
    "        i_t = gates[:, :, :self.hidden_size]\n",
    "        f_t = gates[:, :, self.hidden_size:2 * self.hidden_size]\n",
    "        o_t = gates[:, :, -self.hidden_size:]\n",
    "        c_t = torch.mul(c, f_t) + torch.mul(i_t, g_t)\n",
    "        h_t = torch.mul(o_t, c_t.tanh())\n",
    "        return h_t, c_t\n",
    "\n",
    "class GroupGRUCell(nn.Module):\n",
    "    \"\"\"\n",
    "    GroupGRUCell can compute the operation of N GRU Cells at once.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_grus):\n",
    "        super(GroupGRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.x2h = GroupLinearLayer(input_size, 3 * hidden_size, num_grus)\n",
    "        self.h2h = GroupLinearLayer(hidden_size, 3 * hidden_size, num_grus)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data = torch.ones(w.data.size())\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        input: x (batch_size, num_grus, input_size)\n",
    "               hidden (batch_size, num_grus, hidden_size)\n",
    "        output: hidden (batch_size, num_grus, hidden_size)\n",
    "        \"\"\"\n",
    "        gate_x = self.x2h(x)\n",
    "        gate_h = self.h2h(hidden)\n",
    "        i_r, i_i, i_n = gate_x.chunk(3, 2)\n",
    "        h_r, h_i, h_n = gate_h.chunk(3, 2)\n",
    "        resetgate = torch.sigmoid(i_r + h_r)\n",
    "        inputgate = torch.sigmoid(i_i + h_i)\n",
    "        newgate = torch.tanh(i_n + (resetgate * h_n))\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "        return hy\n",
    "\n",
    "class RIMCell(nn.Module):\n",
    "    def __init__(self, \n",
    "        device, input_size, hidden_size, num_units, k, rnn_cell, input_key_size = 64, input_value_size = 400, input_query_size = 64,\n",
    "        num_input_heads = 1, input_dropout = 0.1, comm_key_size = 32, comm_value_size = 100, comm_query_size = 32, num_comm_heads = 4, comm_dropout = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if comm_value_size != hidden_size:\n",
    "            comm_value_size = hidden_size\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_units = num_units\n",
    "        self.rnn_cell = rnn_cell\n",
    "        self.key_size = input_key_size\n",
    "        self.k = k\n",
    "        self.num_input_heads = num_input_heads\n",
    "        self.num_comm_heads = num_comm_heads\n",
    "        self.input_key_size = input_key_size\n",
    "        self.input_query_size = input_query_size\n",
    "        self.input_value_size = input_value_size\n",
    "        self.comm_key_size = comm_key_size\n",
    "        self.comm_query_size = comm_query_size\n",
    "        self.comm_value_size = comm_value_size\n",
    "        self.key = nn.Linear(input_size, num_input_heads * input_query_size).to(self.device)\n",
    "        self.value = nn.Linear(input_size, num_input_heads * input_value_size).to(self.device)\n",
    "        if self.rnn_cell == 'GRU':\n",
    "            self.rnn = GroupGRUCell(input_value_size, hidden_size, num_units)\n",
    "            self.query = GroupLinearLayer(hidden_size, input_key_size * num_input_heads, self.num_units)\n",
    "        else:\n",
    "            self.rnn = GroupLSTMCell(input_value_size, hidden_size, num_units)\n",
    "            self.query = GroupLinearLayer(hidden_size, input_key_size * num_input_heads, self.num_units)\n",
    "        self.query_ = GroupLinearLayer(hidden_size, comm_query_size * num_comm_heads, self.num_units)\n",
    "        self.key_ = GroupLinearLayer(hidden_size, comm_key_size * num_comm_heads, self.num_units)\n",
    "        self.value_ = GroupLinearLayer(hidden_size, comm_value_size * num_comm_heads, self.num_units)\n",
    "        self.comm_attention_output = GroupLinearLayer(num_comm_heads * comm_value_size, comm_value_size, self.num_units)\n",
    "        self.comm_dropout = nn.Dropout(p=input_dropout)\n",
    "        self.input_dropout = nn.Dropout(p=comm_dropout)\n",
    "\n",
    "    def transpose_for_scores(self, x, num_attention_heads, attention_head_size):\n",
    "        new_x_shape = x.size()[:-1] + (num_attention_heads, attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def input_attention_mask(self, x, h):\n",
    "        \"\"\"\n",
    "        Input : x (batch_size, 2, input_size) [The null input is appended along the first dimension]\n",
    "                h (batch_size, num_units, hidden_size)\n",
    "        Output: inputs (list of size num_units with each element of shape (batch_size, input_value_size))\n",
    "                mask_ binary array of shape (batch_size, num_units) where 1 indicates active and 0 indicates inactive\n",
    "        \"\"\"\n",
    "        key_layer = self.key(x)\n",
    "        value_layer = self.value(x)\n",
    "        query_layer = self.query(h)\n",
    "        key_layer = self.transpose_for_scores(key_layer, self.num_input_heads, self.input_key_size)\n",
    "        value_layer = torch.mean(self.transpose_for_scores(value_layer, self.num_input_heads, self.input_value_size), dim=1)\n",
    "        query_layer = self.transpose_for_scores(query_layer, self.num_input_heads, self.input_query_size)\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2)) / math.sqrt(self.input_key_size)\n",
    "        attention_scores = torch.mean(attention_scores, dim=1)\n",
    "        mask_ = torch.zeros(x.size(0), self.num_units).to(self.device)\n",
    "        not_null_scores = attention_scores[:, :, 0]\n",
    "        topk1 = torch.topk(not_null_scores, self.k, dim=1)\n",
    "        row_index = np.arange(x.size(0))\n",
    "        row_index = np.repeat(row_index, self.k)\n",
    "        mask_[row_index, topk1.indices.view(-1)] = 1\n",
    "        attention_probs = self.input_dropout(nn.Softmax(dim=-1)(attention_scores))\n",
    "        inputs = torch.matmul(attention_probs, value_layer) * mask_.unsqueeze(2)\n",
    "        return inputs, mask_\n",
    "\n",
    "    def communication_attention(self, h, mask):\n",
    "        \"\"\"\n",
    "        Input : h (batch_size, num_units, hidden_size)\n",
    "                mask obtained from the input_attention_mask() function\n",
    "        Output: context_layer (batch_size, num_units, hidden_size). New hidden states after communication\n",
    "        \"\"\"\n",
    "        query_layer = []\n",
    "        key_layer = []\n",
    "        value_layer = []\n",
    "        query_layer = self.query_(h)\n",
    "        key_layer = self.key_(h)\n",
    "        value_layer = self.value_(h)\n",
    "        query_layer = self.transpose_for_scores(query_layer, self.num_comm_heads, self.comm_query_size)\n",
    "        key_layer = self.transpose_for_scores(key_layer, self.num_comm_heads, self.comm_key_size)\n",
    "        value_layer = self.transpose_for_scores(value_layer, self.num_comm_heads, self.comm_value_size)\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.comm_key_size)\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        mask = [mask for _ in range(attention_probs.size(1))]\n",
    "        mask = torch.stack(mask, dim=1)\n",
    "        attention_probs = attention_probs * mask.unsqueeze(3)\n",
    "        attention_probs = self.comm_dropout(attention_probs)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.num_comm_heads * self.comm_value_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        context_layer = self.comm_attention_output(context_layer)\n",
    "        context_layer = context_layer + h\n",
    "        return context_layer\n",
    "\n",
    "    def forward(self, x, hs, cs=None):\n",
    "        \"\"\"\n",
    "        Input : x (batch_size, 1 , input_size)\n",
    "                hs (batch_size, num_units, hidden_size)\n",
    "                cs (batch_size, num_units, hidden_size)\n",
    "        Output: new hs, cs for LSTM\n",
    "                new hs for GRU\n",
    "        \"\"\"\n",
    "        size = x.size()\n",
    "        null_input = torch.zeros(size[0], 1, size[2]).float().to(self.device)\n",
    "        x = torch.cat((x, null_input), dim=1)\n",
    "        inputs, mask = self.input_attention_mask(x, hs)\n",
    "        h_old = hs * 1.0\n",
    "        if cs is not None:\n",
    "            c_old = cs * 1.0\n",
    "        if cs is not None:\n",
    "            hs, cs = self.rnn(inputs, (hs, cs))\n",
    "        else:\n",
    "            hs = self.rnn(inputs, hs)\n",
    "        mask = mask.unsqueeze(2)\n",
    "        h_new = blocked_grad.apply(hs, mask)\n",
    "        h_new = self.communication_attention(h_new, mask.squeeze(2))\n",
    "        hs = mask * h_new + (1 - mask) * h_old\n",
    "        if cs is not None:\n",
    "            cs = mask * cs + (1 - mask) * c_old\n",
    "            return hs, cs\n",
    "        return hs, None\n",
    "\n",
    "class RIM(nn.Module):\n",
    "    def __init__(self, device, input_size, hidden_size, num_units, k, rnn_cell, n_layers, bidirectional, **kwargs):\n",
    "        super().__init__()\n",
    "        if device == 'cuda':\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.n_layers = n_layers\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.rnn_cell = rnn_cell\n",
    "        self.num_units = num_units\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.num_directions == 2:\n",
    "            self.rimcell = nn.ModuleList([RIMCell(self.device, input_size, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) if i < 2 else\n",
    "                                          RIMCell(self.device, 2 * hidden_size * self.num_units, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) for i in range(self.n_layers * self.num_directions)])\n",
    "        else:\n",
    "            self.rimcell = nn.ModuleList([RIMCell(self.device, input_size, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) if i == 0 else\n",
    "                                          RIMCell(self.device, hidden_size * self.num_units, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) for i in range(self.n_layers)])\n",
    "\n",
    "    def layer(self, rim_layer, x, h, c=None, direction=0):\n",
    "        batch_size = x.size(1)\n",
    "\n",
    "        # Debugging: Print input shapes\n",
    "        #print(f\"layer - Initial x shape: {x.shape}\")\n",
    "        #print(f\"layer - Initial h shape: {h.shape}\")\n",
    "        #if c is not None:\n",
    "            #print(f\"layer - Initial c shape: {c.shape}\")\n",
    "\n",
    "        xs = list(torch.split(x, 1, dim=0))\n",
    "        if direction == 1:\n",
    "            xs.reverse()\n",
    "\n",
    "        hs = h.squeeze(0).view(batch_size, self.num_units, -1)\n",
    "\n",
    "        # Debugging: Print reshaped hs shape\n",
    "        #print(f\"layer - Reshaped hs shape: {hs.shape}\")\n",
    "\n",
    "        cs = None\n",
    "        if c is not None:\n",
    "            cs = c.squeeze(0).view(batch_size, self.num_units, -1)\n",
    "            # Debugging: Print reshaped cs shape\n",
    "            #print(f\"layer - Reshaped cs shape: {cs.shape}\")\n",
    "\n",
    "        outputs = []\n",
    "        for x in xs:\n",
    "            x = x.squeeze(0)\n",
    "\n",
    "            # Debugging: Print shape before rim_layer call\n",
    "            #print(f\"layer - x shape before rim_layer: {x.shape}\")\n",
    "            #print(f\"layer - hs shape before rim_layer: {hs.shape}\")\n",
    "            #if cs is not None:\n",
    "                #print(f\"layer - cs shape before rim_layer: {cs.shape}\")\n",
    "\n",
    "            hs, cs = rim_layer(x.unsqueeze(1), hs, cs)\n",
    "\n",
    "            # Debugging: Print shape after rim_layer call\n",
    "            #print(f\"layer - hs shape after rim_layer: {hs.shape}\")\n",
    "            #if cs is not None:\n",
    "                #print(f\"layer - cs shape after rim_layer: {cs.shape}\")\n",
    "\n",
    "            outputs.append(hs.view(1, batch_size, -1))\n",
    "\n",
    "        if direction == 1:\n",
    "            outputs.reverse()\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "\n",
    "        # Debugging: Print final outputs shape\n",
    "        #print(f\"layer - Final outputs shape: {outputs.shape}\")\n",
    "\n",
    "        if c is not None:\n",
    "            return outputs, hs.view(batch_size, -1), cs.view(batch_size, -1)\n",
    "        else:\n",
    "            return outputs, hs.view(batch_size, -1)\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        \"\"\"\n",
    "        Input: x (seq_len, batch_size, feature_size)\n",
    "               h (num_layers * num_directions, batch_size, hidden_size * num_units)\n",
    "               c (num_layers * num_directions, batch_size, hidden_size * num_units)\n",
    "        Output: outputs (batch_size, seqlen, hidden_size * num_units * num-directions)\n",
    "                h(and c) (num_layer * num_directions, batch_size, hidden_size* num_units)\n",
    "        \"\"\"\n",
    "\n",
    "        # Flatten the input image to match RIM input shape\n",
    "        # x = x.view(x.size(0), x.size(1), -1)  # (1, 3, 224*224) -> (1, 1, 3*224*224)\n",
    "\n",
    "        hs = torch.split(h, 1, 0) if h is not None else torch.split(torch.randn(self.n_layers * self.num_directions, x.size(1), self.hidden_size * self.num_units).to(self.device), 1, 0)\n",
    "        hs = list(hs)\n",
    "        cs = None\n",
    "        if self.rnn_cell == 'LSTM':\n",
    "            cs = torch.split(c, 1, 0) if c is not None else torch.split(torch.randn(self.n_layers * self.num_directions, x.size(1), self.hidden_size * self.num_units).to(self.device), 1, 0)\n",
    "            cs = list(cs)\n",
    "        for n in range(self.n_layers):\n",
    "            idx = n * self.num_directions\n",
    "            if cs is not None:\n",
    "                x_fw, hs[idx], cs[idx] = self.layer(self.rimcell[idx], x, hs[idx], cs[idx])\n",
    "            else:\n",
    "                x_fw, hs[idx] = self.layer(self.rimcell[idx], x, hs[idx], c=None)\n",
    "            if self.num_directions == 2:\n",
    "                idx = n * self.num_directions + 1\n",
    "                if cs is not None:\n",
    "                    x_bw, hs[idx], cs[idx] = self.layer(self.rimcell[idx], x, hs[idx], cs[idx], direction=1)\n",
    "                else:\n",
    "                    x_bw, hs[idx] = self.layer(self.rimcell[idx], x, hs[idx], c=None, direction=1)\n",
    "                x = torch.cat((x_fw, x_bw), dim=2)\n",
    "            else:\n",
    "                x = x_fw\n",
    "        hs = torch.stack(hs, dim=0)\n",
    "        if cs is not None:\n",
    "            cs = torch.stack(cs, dim=0)\n",
    "            return x, hs, cs\n",
    "        return x, hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxlU46PFgdSd"
   },
   "source": [
    "## MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1715970681225,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "tNxMhrlyj5IW"
   },
   "outputs": [],
   "source": [
    "# define some image augmentations\n",
    "\n",
    "def vertical_flip(img):\n",
    "    img = TF.to_pil_image(img)\n",
    "    res = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    return TF.to_tensor(res)\n",
    "\n",
    "def brightness(img, factor_range=(0.5, 1.5)):\n",
    "  img = TF.to_pil_image(img)\n",
    "  factor = np.random.uniform(factor_range[0], factor_range[1])\n",
    "  enhancer = ImageEnhance.Brightness(img)\n",
    "  res = enhancer.enhance(factor)\n",
    "  return TF.to_tensor(res)\n",
    "\n",
    "'''\n",
    "def rotation(img, angle_range=(-45, 45)):\n",
    "  angle = np.random.uniform(angle_range[0], angle_range[1])\n",
    "  return img.rotate(angle)\n",
    "'''\n",
    "\n",
    "def color(img, factor_range=(0.5, 1.5)):\n",
    "  img = TF.to_pil_image(img)\n",
    "  factor = np.random.uniform(factor_range[0], factor_range[1])\n",
    "  enhancer = ImageEnhance.Color(img)\n",
    "  res = enhancer.enhance(factor)\n",
    "  return TF.to_tensor(res)\n",
    "\n",
    "def sharpness(img, factor_range=(0.5, 1.5)):\n",
    "  img = TF.to_pil_image(img)\n",
    "  factor = np.random.uniform(factor_range[0], factor_range[1])\n",
    "  enhancer = ImageEnhance.Sharpness(img)\n",
    "  res = enhancer.enhance(factor)\n",
    "  return TF.to_tensor(res)\n",
    "\n",
    "augmentations = [vertical_flip, brightness, color, sharpness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1715970684858,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "9WXWL3Gxh3Cr"
   },
   "outputs": [],
   "source": [
    "def augment_image_rims(img, augmentations, rims, B=15):\n",
    "    assert len(augmentations) > 0, \"No augmentations provided.\"\n",
    "    images = [img]\n",
    "    aug_names = []  # List to store augmentation names\n",
    "    aug_factors = []  # List to store augmentation factors\n",
    "\n",
    "    device = rims.device  # Ensure device is defined\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img_tensor = img.unsqueeze(0).to(device)\n",
    "    else:\n",
    "        img_tensor = TF.to_tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "    batch_size = img_tensor.size(0)\n",
    "    input_size = img_tensor.size(1) * img_tensor.size(2) * img_tensor.size(3)\n",
    "    img_tensor = img_tensor.view(1, 1, input_size)\n",
    "\n",
    "    h = torch.zeros(rims.n_layers * rims.num_directions, batch_size, rims.hidden_size * rims.num_units).to(device)\n",
    "    c = torch.zeros(rims.n_layers * rims.num_directions, batch_size, rims.hidden_size * rims.num_units).to(device)\n",
    "\n",
    "    linear = nn.Linear(rims.hidden_size * rims.num_units, len(augmentations)).to(device)\n",
    "\n",
    "    for i in range(B):\n",
    "        outputs, h, c = rims(img_tensor, h, c)\n",
    "\n",
    "        preds = linear(outputs)\n",
    "        attention_weights = torch.softmax(preds, dim=-1)\n",
    "        hyperparameters = torch.tanh(outputs).mean(dim=-1)\n",
    "\n",
    "        aug_idx = torch.multinomial(attention_weights.squeeze(), 1).item()\n",
    "        augmentation = augmentations[aug_idx]\n",
    "\n",
    "        if augmentation.__name__ in ['brightness', 'color', 'sharpness']:\n",
    "            factor = (hyperparameters[0].item() + 1) / 2\n",
    "            diverse_factor = random.uniform(0.5, 1.5)  # Generate a random factor between 0.5 and 1.5 for diversity\n",
    "            augmented_img = augmentation(img, factor_range=(factor * diverse_factor, factor * diverse_factor))\n",
    "            aug_factors.append(factor * diverse_factor)\n",
    "        else:\n",
    "            augmented_img = augmentation(img)\n",
    "            aug_factors.append(None)\n",
    "\n",
    "        images.append(augmented_img)\n",
    "        aug_names.append(augmentation.__name__)  # Store the augmentation name\n",
    "\n",
    "        # Print the image every 10 iterations\n",
    "        #if i % 10 == 0:\n",
    "            #fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            #axs[0].imshow(TF.to_pil_image(img))\n",
    "            #axs[0].set_title(\"Original Image\")\n",
    "            #axs[0].axis('off')\n",
    "            #axs[1].imshow(TF.to_pil_image(augmented_img))\n",
    "            #axs[1].set_title(f\"Iteration {i} - Augmented: {augmentation.__name__}\")\n",
    "            #axs[1].axis('off')\n",
    "            #plt.show()\n",
    "\n",
    "    # Create a summary table\n",
    "    df_aug_summary = pd.DataFrame({'Augmentation': aug_names, 'Factor': aug_factors})\n",
    "\n",
    "    return images, df_aug_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, augmentations, B=15):\n",
    "    assert len(augmentations) > 0, \"There are no augmentations provided.\"\n",
    "\n",
    "    images = [img]\n",
    "    aug_names = []  # List to store augmentation names\n",
    "    aug_factors = []  # List to store augmentation factors\n",
    "\n",
    "    for i in range(B):\n",
    "        # Randomly choose an augmentation from the augmentation functions\n",
    "        index = random.randrange(0, len(augmentations))\n",
    "        augmentation = augmentations[index]\n",
    "        \n",
    "        if augmentation.__name__ in ['brightness', 'color', 'sharpness']:\n",
    "            factor = random.uniform(0.5, 1.5)  # Generate a random factor between 0.5 and 1.5\n",
    "            augmented_img = augmentation(img, factor_range=(factor, factor))\n",
    "            aug_factors.append(factor)\n",
    "        else:\n",
    "            augmented_img = augmentation(img)\n",
    "            aug_factors.append(None)\n",
    "        \n",
    "        # Add the augmented image to the list of images to evaluate\n",
    "        images.append(augmented_img)\n",
    "        aug_names.append(augmentation.__name__)  # Store the augmentation name\n",
    "\n",
    "        # Print the image every 10 iterations\n",
    "        #if i % 10 == 0 and i != 0:\n",
    "            #plt.imshow(augmented_img.permute(1, 2, 0))\n",
    "            #plt.title(f\"Iteration {i} - Augmentation: {augmentation.__name__}\")\n",
    "            #plt.show()\n",
    "\n",
    "    # Create a summary table\n",
    "    df_aug_summary = pd.DataFrame({'Augmentation': aug_names, 'Factor': aug_factors})\n",
    "    print(\"\\nAugmentation Summary Table:\")\n",
    "    print(df_aug_summary)\n",
    "\n",
    "    print(\"Number of images:\", len(images))\n",
    "\n",
    "    return images, df_aug_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1715970687565,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "xc5j-FiVdoBs"
   },
   "outputs": [],
   "source": [
    "# define the cost function used to evaluate the model output\n",
    "def get_cost_function():\n",
    "  cost_function = torch.nn.CrossEntropyLoss()\n",
    "  return cost_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1715970701773,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "pxiafvsgPisv"
   },
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "def get_optimizer(net, lr, wd, momentum):\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1715970703645,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "bhN-AaM_huqQ"
   },
   "outputs": [],
   "source": [
    "# compute the marginal output distribution\n",
    "def marginal_distribution(images, model, transforms, device):\n",
    "  # collect the prediction for every image in input\n",
    "  img_results = []\n",
    "  for img in images:\n",
    "    single_batch = transforms(img).unsqueeze(0).to(device)\n",
    "    prediction = model(single_batch).squeeze(0).softmax(0)\n",
    "    img_results.append(prediction)\n",
    "\n",
    "  # sum all the resulting tensors\n",
    "  sum_results = torch.sum(torch.stack(img_results), dim=0).to(device)\n",
    "  # divide each element by B to obtain the marginal output distribution\n",
    "  num_images = len(images)\n",
    "  res = torch.div(sum_results, num_images).to(device)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1715971147154,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "lq-B2QHFufkB"
   },
   "outputs": [],
   "source": [
    "# compute the marginal cross entropy\n",
    "def marginal_cross_entropy(marginal_dist, labels, cost_function):\n",
    "  entropy = 0.0\n",
    "  # sum all entropies for the different labels since I don't know the real one\n",
    "  for label in labels:\n",
    "    entropy += cost_function(marginal_dist, label)\n",
    "  return entropy\n",
    "\n",
    "\n",
    "def marginal_cross_entropy(marginal_dist, labels, cost_function):\n",
    "    entropy = 0.0\n",
    "    for label in labels:\n",
    "        entropy += cost_function(marginal_dist, label)\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1715971150673,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "_cmtwAFRFCoW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def ttr_MEMO_with_rims(model, test_sample, labels, B, cost_function, optimizer, transforms, device, rims):\n",
    "    original_params = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        augmented_images, summary_table = augment_image_rims(test_sample, augmentations, rims, B)\n",
    "        marginal_dist = marginal_distribution(augmented_images, model, transforms, device)\n",
    "        \n",
    "        loss = marginal_cross_entropy(marginal_dist, labels, cost_function)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    test_sample = transforms(test_sample).unsqueeze(0).to(device)\n",
    "    output = model(test_sample).squeeze(0).softmax(0)\n",
    "    model.load_state_dict(original_params)\n",
    "    \n",
    "    return output, summary_table\n",
    "\n",
    "\n",
    "def test_with_rims(model, data_loader, B, cost_function, optimizer, transforms, device, rims):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "    all_summary_tables = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Testing\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            batch_size = inputs.size(0)\n",
    "            intermediate_outputs = []\n",
    "            for input in inputs:\n",
    "                output, summary_table = ttr_MEMO_with_rims(model, input, targets, B, cost_function, optimizer, transforms, device, rims)\n",
    "                intermediate_outputs.append(output)\n",
    "                all_summary_tables.append(summary_table)  # Collect summary table for each test sample\n",
    "\n",
    "            outputs = torch.stack(intermediate_outputs).to(device)\n",
    "            loss = cost_function(outputs, targets)\n",
    "\n",
    "            samples += inputs.shape[0]\n",
    "            cumulative_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    combined_summary_table = pd.concat(all_summary_tables, ignore_index=True)  # Concatenate all summary tables\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100, combined_summary_table\n",
    "\n",
    "def main_with_rims(\n",
    "    run_name,\n",
    "    batch_size=32,  # Adjusted batch size\n",
    "    device=\"cuda\",\n",
    "    learning_rate=0.0001,  # Reduced learning rate\n",
    "    weight_decay=0.00001,  # Adjusted weight decay\n",
    "    momentum=0.9,\n",
    "    num_augmentations=15\n",
    "):\n",
    "    device = torch.device(device)\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights).to(device)\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Initialize the test dataloader\n",
    "    test_loader, _ = get_data(batch_size, data_folder, preprocess)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = get_optimizer(model, learning_rate, weight_decay, momentum)\n",
    "\n",
    "    # Initialize the cost function\n",
    "    cost_function = get_cost_function()\n",
    "\n",
    "    # Get a sample image to determine the input dimension\n",
    "    sample_img, _ = next(iter(test_loader))\n",
    "    sample_img = sample_img[0].unsqueeze(0)  # Take one sample and add batch dimension\n",
    "    sample_img = preprocess(sample_img)\n",
    "    input_dim = sample_img.size(1) * sample_img.size(2) * sample_img.size(3)  # Channels * Height * Width\n",
    "\n",
    "    hidden_dim = 128\n",
    "    num_units = 4\n",
    "    k = 2\n",
    "\n",
    "    rims = RIM('cuda', input_dim, hidden_dim, num_units, k, rnn_cell='LSTM', n_layers=2, bidirectional=False).to(device)\n",
    "    print(f\"Initialized RIMs with input_dim={input_dim}, hidden_dim={hidden_dim}, num_units={num_units}, k={k}\")\n",
    "\n",
    "    # Run the test\n",
    "    test_loss, test_accuracy, combined_summary_table = test_with_rims(model, test_loader, num_augmentations, cost_function, optimizer, preprocess, device, rims)\n",
    "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
    "\n",
    "    # Print the combined summary table\n",
    "    print(\"\\nCombined Augmentation Summary Table:\")\n",
    "    print(combined_summary_table)\n",
    "\n",
    "    # Calculate statistics\n",
    "    aug_counts = combined_summary_table['Augmentation'].value_counts().reset_index()\n",
    "    aug_counts.columns = ['Augmentation', 'Count']\n",
    "\n",
    "    aug_factors = combined_summary_table.groupby('Augmentation')['Factor'].mean().reset_index()\n",
    "    aug_factors.columns = ['Augmentation', 'Average Factor']\n",
    "\n",
    "    final_summary = pd.merge(aug_counts, aug_factors, on='Augmentation', how='left')\n",
    "\n",
    "    print(\"\\nFinal Summary Table:\")\n",
    "    print(final_summary)\n",
    "\n",
    "main_with_rims(\"resnet_MEMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test time robustness via MEMO algorithm\n",
    "def ttr_MEMO(model, test_sample, label, B, cost_function, optimizer, transforms, device):\n",
    "    # Save the original model weights\n",
    "    original_params = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        # Get the B + 1 images\n",
    "        augmented_images, summary_table = augment_image(test_sample, augmentations, B)\n",
    "\n",
    "        # Get the marginal output distribution\n",
    "        marginal_dist = marginal_distribution(augmented_images, model, transforms, device)\n",
    "\n",
    "        # Update the model weights\n",
    "        loss = cost_function(marginal_dist, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    test_sample = transforms(test_sample).unsqueeze(0).to(device)\n",
    "    output = model(test_sample).squeeze(0).softmax(0)\n",
    "\n",
    "    # Reapply original weights to the model\n",
    "    model.load_state_dict(original_params)\n",
    "\n",
    "    return output, summary_table\n",
    "\n",
    "def test(model, data_loader, B, cost_function, optimizer, transforms, device=\"cuda\"):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "    all_summary_tables = []\n",
    "\n",
    "    # Set the network to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation for testing mode\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test set with tqdm for progress tracking\n",
    "        for batch_idx, (inputs, targets) in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Testing\", leave=False):\n",
    "            # Load data into GPU\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            batch_size = inputs.size(0)\n",
    "            num_labels = 1000  # 1000 is the ImageNet number of labels\n",
    "\n",
    "            # Apply MEMO to each test point in the batch\n",
    "            intermediate_outputs = []\n",
    "            for input, target in zip(inputs, targets):\n",
    "                output, summary_table = ttr_MEMO(model, input, target, B, cost_function, optimizer, transforms, device)\n",
    "                intermediate_outputs.append(output)\n",
    "                all_summary_tables.append(summary_table)  # Collect summary table for each test sample\n",
    "\n",
    "            outputs = torch.stack(intermediate_outputs).to(device)\n",
    "\n",
    "            # Loss computation\n",
    "            loss = cost_function(outputs, targets)\n",
    "\n",
    "            # Fetch prediction and loss value\n",
    "            samples += inputs.shape[0]\n",
    "            cumulative_loss += loss.item()  # Note: the .item() is needed to extract scalars from tensors\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            # Compute accuracy\n",
    "            cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    combined_summary_table = pd.concat(all_summary_tables, ignore_index=True)  # Concatenate all summary tables\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100, combined_summary_table\n",
    "\n",
    "def main(\n",
    "    run_name,\n",
    "    batch_size = 32,\n",
    "    device = \"cuda\",\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.000001,\n",
    "    momentum=0.9,\n",
    "    num_augmentations = 15\n",
    "):\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Initialize the ResNet model\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights).to(device)\n",
    "\n",
    "    # Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Initialize the test dataloader\n",
    "    test_loader, _ = get_data(batch_size, data_folder, preprocess)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = get_optimizer(model, learning_rate, weight_decay, momentum)\n",
    "\n",
    "    # Initialize the cost function\n",
    "    cost_function = get_cost_function()\n",
    "\n",
    "    test_loss, test_accuracy, combined_summary_table = test(model, test_loader, num_augmentations, cost_function, optimizer, preprocess, device)\n",
    "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
    "\n",
    "    # Print the combined summary table\n",
    "    print(\"\\nCombined Augmentation Summary Table:\")\n",
    "    print(combined_summary_table)\n",
    "\n",
    "    # Calculate statistics\n",
    "    aug_counts = combined_summary_table['Augmentation'].value_counts().reset_index()\n",
    "    aug_counts.columns = ['Augmentation', 'Count']\n",
    "\n",
    "    aug_factors = combined_summary_table.groupby('Augmentation')['Factor'].mean().reset_index()\n",
    "    aug_factors.columns = ['Augmentation', 'Average Factor']\n",
    "\n",
    "    final_summary = pd.merge(aug_counts, aug_factors, on='Augmentation', how='left')\n",
    "\n",
    "    print(\"\\nFinal Summary Table:\")\n",
    "    print(final_summary)\n",
    "\n",
    "main(\"resnet_MEMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
