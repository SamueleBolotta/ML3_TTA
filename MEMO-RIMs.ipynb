{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDYnDRjPfNF_"
   },
   "source": [
    "# DL Project 2023/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ll5uAwzhfYHn"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Description of the method choosen and the work done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision matplotlib tqdm Pillow numpy --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 19732,
     "status": "ok",
     "timestamp": 1715970600487,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "Lw7k2mxRfE1D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuele/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch and related modules\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Import torchvision and related modules\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Import other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import multiprocessing\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37897,
     "status": "ok",
     "timestamp": 1715970642796,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "qQnIh3lo3VAS",
    "outputId": "94b3fb3e-e93d-4bf2-eceb-79b231353554"
   },
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "    tar_file = \"/content/drive/MyDrive/DL_project/imagenet-a.tar\"\n",
    "else:\n",
    "    # Set the path for Jupyter \n",
    "    tar_file = \"./imagenet-a.tar\"\n",
    "\n",
    "data_folder = \"imagenet-a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqX-jwMHgZ3G"
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21703,
     "status": "ok",
     "timestamp": 1715970667457,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "4h7Y7SSrgc7y",
    "outputId": "bd874e65-9065-46ec-947e-8a4ae09e067e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compress file doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "# function to untar the dataset and store it in a new folder\n",
    "def extract_dataset(compress_file, destination_folder):\n",
    "  # function to change dir names to their words description\n",
    "  def change_folders_names(readme_file, dataset_root):\n",
    "    with open(readme_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            # Match lines containing WordNet IDs and descriptions\n",
    "            match = re.match(r'n\\d+ (.+)', line)\n",
    "            if match:\n",
    "                # Split the line into WordNet ID and description\n",
    "                parts = match.group(0).split()\n",
    "                wordnet_id = parts[0]\n",
    "                description = ' '.join(parts[1:])\n",
    "                os.rename(os.path.join(dataset_root, wordnet_id),\n",
    "                            os.path.join(dataset_root, description))\n",
    "\n",
    "  if not os.path.exists(compress_file):\n",
    "    print(\"Compress file doesn't exist.\")\n",
    "    return\n",
    "\n",
    "  if os.path.exists(destination_folder):\n",
    "    # remove the folder if already exists one\n",
    "    shutil.rmtree(destination_folder)\n",
    "\n",
    "  # extract content from the .tar file\n",
    "  with tarfile.open(compress_file, 'r') as tar_ref:\n",
    "    tar_ref.extractall(\"./\")\n",
    "  print(\"All the data is extracted.\")\n",
    "\n",
    "  change_folders_names(destination_folder+\"/README.txt\", destination_folder)\n",
    "\n",
    "extract_dataset(tar_file, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1715970670636,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "rzBAWU06L_Mm",
    "outputId": "2a005eca-33f2-45bb-ea03-a7427ee7fa99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n03291819', 'n04562935', 'n04540053', 'n03125729', 'n02879718', 'n02669723', 'n01770393', 'n02231487', 'n03721384', 'n03617480', 'n01498041', 'n04509417', 'n01986214', 'n03594945', 'n01847000', 'n01819313', 'n01833805', 'n02106662', 'n03325584', 'n02190166', 'n04591713', 'n07718472', 'n02777292', 'n02051845', 'n03891332', 'n02174001', 'n04254120', 'n02037110', 'n02268443', 'n07749582', 'n02486410', 'n03584829', 'n07697537', 'n03196217', 'n01616318', 'n02279972', 'n04131690', 'n09472597', 'n04086273', 'n04456115', 'n02226429', 'n07768694', 'n01855672', 'n03935335', 'n03417042', 'n02361337', 'n02814860', 'n02701002', 'n01687978', 'n07734744', 'n12057211', 'n04347754', 'n02445715', 'n12267677', 'n01910747', 'n01614925', 'n03788195', 'n02730930', 'n02883205', 'n01882714', 'n02787622', 'n04442312', 'n02085620', 'n02797295', 'n01784675', 'n03982430', 'n03124043', 'n02133161', 'n01534433', 'n04019541', 'n02099601', 'n03775071', 'n01669191', 'n04344873', 'n04317175', 'n01735189', 'n02492035', 'n01944390', 'n03483316', 'n02129165', 'n03840681', 'n03014705', 'n02992211', 'n04275548', 'n04208210', 'n04310018', 'n02655020', 'n02951358', 'n02165456', 'n03717622', 'n01820546', 'n02177972', 'n01774750', 'n03837869', 'n04146614', 'n03452741', 'n04141076', 'n07831146', 'n02802426', 'n02123394', 'n03720891', 'n02236044', 'n03443371', 'n03255030', 'n01631663', 'n02206856', 'n02906734', 'n02106550', 'n09229709', 'n02980441', 'n04147183', 'n01694178', 'n02793495', 'n02077923', 'n03888257', 'n03384352', 'n02690373', 'n04067472', 'n02317335', 'n04376876', 'n04133789', 'n03388043', 'n04399382', 'n02454379', 'n02895154', 'n04507155', 'n02356798', 'n02410509', 'n01580077', 'n02280649', 'n12144580', 'n07714990', 'n04033901', 'n02837789', 'README.txt', 'n03026506', 'n02007558', 'n04039381', 'n02119022', 'n02999410', 'n02219486', 'n04482393', 'n01843383', 'n01677366', 'n03223299', 'n04366367', 'n02009912', 'n02782093', 'n02325366', 'n02233338', 'n07697313', 'n03444034', 'n02815834', 'n04235860', 'n02137549', 'n03804744', 'n01914609', 'n04252077', 'n01531178', 'n02676566', 'n09246464', 'n04270147', 'n07760859', 'n01985128', 'n04606251', 'n02948072', 'n03445924', 'n01641577', 'n03854065', 'n02259212', 'n03666591', 'n03355925', 'n04554684', 'n01558993', 'n04099969', 'n02672831', 'n03250847', 'imagenetv2-matched-frequency.tar.gz', 'n04252225', 'n03187595', 'n01924916', 'n09835506', 'n04389033', 'n01770081', 'n02127052', 'n03724870', 'n07695742', 'n04118538', 'n02110958', 'n07753592', 'n03670208', 'n03590841', 'n04355338', 'n11879895', 'n02281787', 'n02346627', 'n01698640', 'n07720875', 'n04532670', 'n07583066', 'n02504458', 'n04179913']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_list = os.listdir(data_folder)\n",
    "print(ids_list)\n",
    "len(ids_list) # 200 folders + 1 readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1715970673171,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "eul04CxP3VaH"
   },
   "outputs": [],
   "source": [
    "# function that returns a DataLoader for the dataset\n",
    "def get_data(batch_size, dataset_path, transform):\n",
    "\n",
    "  data = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "  class_labels = data.classes\n",
    "  print(f\"The dataset contains {len(data)} images.\")\n",
    "  print(f\"The dataset contains {len(class_labels)} labels.\")\n",
    "\n",
    "  test_loader = torch.utils.data.DataLoader(data, batch_size, shuffle=False, num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "  return test_loader, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1715970676875,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "HHAElKCP7mMv"
   },
   "outputs": [],
   "source": [
    "# function to display images from the DataLoader\n",
    "def show_images(dataloader, num_images=5):\n",
    "  # get a batch of data\n",
    "  data_iter = iter(dataloader)\n",
    "  images, labels = next(data_iter)\n",
    "\n",
    "  # convert images to numpy array\n",
    "  images = images.numpy()\n",
    "\n",
    "  # display images\n",
    "  fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "  for i in range(num_images):\n",
    "      image = np.transpose(images[i], (1, 2, 0))  # move channels in last position\n",
    "      image = np.clip(image, 0, 1)\n",
    "      axes[i].imshow(image)\n",
    "      axes[i].axis('off')\n",
    "      axes[i].set_title(dataloader.dataset.classes[labels[i]])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class blocked_grad(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, mask):\n",
    "        ctx.save_for_backward(x, mask)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, mask = ctx.saved_tensors\n",
    "        return grad_output * mask, mask * 0.0\n",
    "\n",
    "class GroupLinearLayer(nn.Module):\n",
    "    def __init__(self, din, dout, num_blocks):\n",
    "        super(GroupLinearLayer, self).__init__()\n",
    "        self.w = nn.Parameter(0.01 * torch.randn(num_blocks, din, dout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = torch.bmm(x, self.w)\n",
    "        return x.permute(1, 0, 2)\n",
    "\n",
    "class GroupLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    GroupLSTMCell can compute the operation of N LSTM Cells at once.\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_size, hidden_size, num_lstms):\n",
    "        super().__init__()\n",
    "        self.inp_size = inp_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = GroupLinearLayer(inp_size, 4 * hidden_size, num_lstms)\n",
    "        self.h2h = GroupLinearLayer(hidden_size, 4 * hidden_size, num_lstms)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, hid_state):\n",
    "        \"\"\"\n",
    "        input: x (batch_size, num_lstms, input_size)\n",
    "               hid_state (tuple of length 2 with each element of size (batch_size, num_lstms, hidden_state))\n",
    "        output: h (batch_size, num_lstms, hidden_state)\n",
    "                c ((batch_size, num_lstms, hidden_state))\n",
    "        \"\"\"\n",
    "        h, c = hid_state\n",
    "        preact = self.i2h(x) + self.h2h(h)\n",
    "        gates = preact[:, :, :3 * self.hidden_size].sigmoid()\n",
    "        g_t = preact[:, :, 3 * self.hidden_size:].tanh()\n",
    "        i_t = gates[:, :, :self.hidden_size]\n",
    "        f_t = gates[:, :, self.hidden_size:2 * self.hidden_size]\n",
    "        o_t = gates[:, :, -self.hidden_size:]\n",
    "        c_t = torch.mul(c, f_t) + torch.mul(i_t, g_t)\n",
    "        h_t = torch.mul(o_t, c_t.tanh())\n",
    "        return h_t, c_t\n",
    "\n",
    "class GroupGRUCell(nn.Module):\n",
    "    \"\"\"\n",
    "    GroupGRUCell can compute the operation of N GRU Cells at once.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_grus):\n",
    "        super(GroupGRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.x2h = GroupLinearLayer(input_size, 3 * hidden_size, num_grus)\n",
    "        self.h2h = GroupLinearLayer(hidden_size, 3 * hidden_size, num_grus)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data = torch.ones(w.data.size())\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        input: x (batch_size, num_grus, input_size)\n",
    "               hidden (batch_size, num_grus, hidden_size)\n",
    "        output: hidden (batch_size, num_grus, hidden_size)\n",
    "        \"\"\"\n",
    "        gate_x = self.x2h(x)\n",
    "        gate_h = self.h2h(hidden)\n",
    "        i_r, i_i, i_n = gate_x.chunk(3, 2)\n",
    "        h_r, h_i, h_n = gate_h.chunk(3, 2)\n",
    "        resetgate = torch.sigmoid(i_r + h_r)\n",
    "        inputgate = torch.sigmoid(i_i + h_i)\n",
    "        newgate = torch.tanh(i_n + (resetgate * h_n))\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "        return hy\n",
    "\n",
    "class RIMCell(nn.Module):\n",
    "    def __init__(self, \n",
    "        device, input_size, hidden_size, num_units, k, rnn_cell, input_key_size = 64, input_value_size = 400, input_query_size = 64,\n",
    "        num_input_heads = 1, input_dropout = 0.1, comm_key_size = 32, comm_value_size = 100, comm_query_size = 32, num_comm_heads = 4, comm_dropout = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if comm_value_size != hidden_size:\n",
    "            comm_value_size = hidden_size\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_units = num_units\n",
    "        self.rnn_cell = rnn_cell\n",
    "        self.key_size = input_key_size\n",
    "        self.k = k\n",
    "        self.num_input_heads = num_input_heads\n",
    "        self.num_comm_heads = num_comm_heads\n",
    "        self.input_key_size = input_key_size\n",
    "        self.input_query_size = input_query_size\n",
    "        self.input_value_size = input_value_size\n",
    "        self.comm_key_size = comm_key_size\n",
    "        self.comm_query_size = comm_query_size\n",
    "        self.comm_value_size = comm_value_size\n",
    "        self.key = nn.Linear(input_size, num_input_heads * input_query_size).to(self.device)\n",
    "        self.value = nn.Linear(input_size, num_input_heads * input_value_size).to(self.device)\n",
    "        if self.rnn_cell == 'GRU':\n",
    "            self.rnn = GroupGRUCell(input_value_size, hidden_size, num_units)\n",
    "            self.query = GroupLinearLayer(hidden_size, input_key_size * num_input_heads, self.num_units)\n",
    "        else:\n",
    "            self.rnn = GroupLSTMCell(input_value_size, hidden_size, num_units)\n",
    "            self.query = GroupLinearLayer(hidden_size, input_key_size * num_input_heads, self.num_units)\n",
    "        self.query_ = GroupLinearLayer(hidden_size, comm_query_size * num_comm_heads, self.num_units)\n",
    "        self.key_ = GroupLinearLayer(hidden_size, comm_key_size * num_comm_heads, self.num_units)\n",
    "        self.value_ = GroupLinearLayer(hidden_size, comm_value_size * num_comm_heads, self.num_units)\n",
    "        self.comm_attention_output = GroupLinearLayer(num_comm_heads * comm_value_size, comm_value_size, self.num_units)\n",
    "        self.comm_dropout = nn.Dropout(p=input_dropout)\n",
    "        self.input_dropout = nn.Dropout(p=comm_dropout)\n",
    "\n",
    "    def transpose_for_scores(self, x, num_attention_heads, attention_head_size):\n",
    "        new_x_shape = x.size()[:-1] + (num_attention_heads, attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def input_attention_mask(self, x, h):\n",
    "        \"\"\"\n",
    "        Input : x (batch_size, 2, input_size) [The null input is appended along the first dimension]\n",
    "                h (batch_size, num_units, hidden_size)\n",
    "        Output: inputs (list of size num_units with each element of shape (batch_size, input_value_size))\n",
    "                mask_ binary array of shape (batch_size, num_units) where 1 indicates active and 0 indicates inactive\n",
    "        \"\"\"\n",
    "        key_layer = self.key(x)\n",
    "        value_layer = self.value(x)\n",
    "        query_layer = self.query(h)\n",
    "        key_layer = self.transpose_for_scores(key_layer, self.num_input_heads, self.input_key_size)\n",
    "        value_layer = torch.mean(self.transpose_for_scores(value_layer, self.num_input_heads, self.input_value_size), dim=1)\n",
    "        query_layer = self.transpose_for_scores(query_layer, self.num_input_heads, self.input_query_size)\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2)) / math.sqrt(self.input_key_size)\n",
    "        attention_scores = torch.mean(attention_scores, dim=1)\n",
    "        mask_ = torch.zeros(x.size(0), self.num_units).to(self.device)\n",
    "        not_null_scores = attention_scores[:, :, 0]\n",
    "        topk1 = torch.topk(not_null_scores, self.k, dim=1)\n",
    "        row_index = np.arange(x.size(0))\n",
    "        row_index = np.repeat(row_index, self.k)\n",
    "        mask_[row_index, topk1.indices.view(-1)] = 1\n",
    "        attention_probs = self.input_dropout(nn.Softmax(dim=-1)(attention_scores))\n",
    "        inputs = torch.matmul(attention_probs, value_layer) * mask_.unsqueeze(2)\n",
    "        return inputs, mask_\n",
    "\n",
    "    def communication_attention(self, h, mask):\n",
    "        \"\"\"\n",
    "        Input : h (batch_size, num_units, hidden_size)\n",
    "                mask obtained from the input_attention_mask() function\n",
    "        Output: context_layer (batch_size, num_units, hidden_size). New hidden states after communication\n",
    "        \"\"\"\n",
    "        query_layer = []\n",
    "        key_layer = []\n",
    "        value_layer = []\n",
    "        query_layer = self.query_(h)\n",
    "        key_layer = self.key_(h)\n",
    "        value_layer = self.value_(h)\n",
    "        query_layer = self.transpose_for_scores(query_layer, self.num_comm_heads, self.comm_query_size)\n",
    "        key_layer = self.transpose_for_scores(key_layer, self.num_comm_heads, self.comm_key_size)\n",
    "        value_layer = self.transpose_for_scores(value_layer, self.num_comm_heads, self.comm_value_size)\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.comm_key_size)\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        mask = [mask for _ in range(attention_probs.size(1))]\n",
    "        mask = torch.stack(mask, dim=1)\n",
    "        attention_probs = attention_probs * mask.unsqueeze(3)\n",
    "        attention_probs = self.comm_dropout(attention_probs)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.num_comm_heads * self.comm_value_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        context_layer = self.comm_attention_output(context_layer)\n",
    "        context_layer = context_layer + h\n",
    "        return context_layer\n",
    "\n",
    "    def forward(self, x, hs, cs=None):\n",
    "        \"\"\"\n",
    "        Input : x (batch_size, 1 , input_size)\n",
    "                hs (batch_size, num_units, hidden_size)\n",
    "                cs (batch_size, num_units, hidden_size)\n",
    "        Output: new hs, cs for LSTM\n",
    "                new hs for GRU\n",
    "        \"\"\"\n",
    "        size = x.size()\n",
    "        null_input = torch.zeros(size[0], 1, size[2]).float().to(self.device)\n",
    "        x = torch.cat((x, null_input), dim=1)\n",
    "        inputs, mask = self.input_attention_mask(x, hs)\n",
    "        h_old = hs * 1.0\n",
    "        if cs is not None:\n",
    "            c_old = cs * 1.0\n",
    "        if cs is not None:\n",
    "            hs, cs = self.rnn(inputs, (hs, cs))\n",
    "        else:\n",
    "            hs = self.rnn(inputs, hs)\n",
    "        mask = mask.unsqueeze(2)\n",
    "        h_new = blocked_grad.apply(hs, mask)\n",
    "        h_new = self.communication_attention(h_new, mask.squeeze(2))\n",
    "        hs = mask * h_new + (1 - mask) * h_old\n",
    "        if cs is not None:\n",
    "            cs = mask * cs + (1 - mask) * c_old\n",
    "            return hs, cs\n",
    "        return hs, None\n",
    "\n",
    "class RIM(nn.Module):\n",
    "    def __init__(self, device, input_size, hidden_size, num_units, k, rnn_cell, n_layers, bidirectional, **kwargs):\n",
    "        super().__init__()\n",
    "        if device == 'cuda':\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.n_layers = n_layers\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.rnn_cell = rnn_cell\n",
    "        self.num_units = num_units\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.num_directions == 2:\n",
    "            self.rimcell = nn.ModuleList([RIMCell(self.device, input_size, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) if i < 2 else\n",
    "                                          RIMCell(self.device, 2 * hidden_size * self.num_units, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) for i in range(self.n_layers * self.num_directions)])\n",
    "        else:\n",
    "            self.rimcell = nn.ModuleList([RIMCell(self.device, input_size, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) if i == 0 else\n",
    "                                          RIMCell(self.device, hidden_size * self.num_units, hidden_size, num_units, k, rnn_cell, **kwargs).to(self.device) for i in range(self.n_layers)])\n",
    "\n",
    "    def layer(self, rim_layer, x, h, c=None, direction=0):\n",
    "        batch_size = x.size(1)\n",
    "\n",
    "        # Debugging: Print input shapes\n",
    "        print(f\"layer - Initial x shape: {x.shape}\")\n",
    "        print(f\"layer - Initial h shape: {h.shape}\")\n",
    "        if c is not None:\n",
    "            print(f\"layer - Initial c shape: {c.shape}\")\n",
    "\n",
    "        xs = list(torch.split(x, 1, dim=0))\n",
    "        if direction == 1:\n",
    "            xs.reverse()\n",
    "\n",
    "        hs = h.squeeze(0).view(batch_size, self.num_units, -1)\n",
    "\n",
    "        # Debugging: Print reshaped hs shape\n",
    "        print(f\"layer - Reshaped hs shape: {hs.shape}\")\n",
    "\n",
    "        cs = None\n",
    "        if c is not None:\n",
    "            cs = c.squeeze(0).view(batch_size, self.num_units, -1)\n",
    "            # Debugging: Print reshaped cs shape\n",
    "            print(f\"layer - Reshaped cs shape: {cs.shape}\")\n",
    "\n",
    "        outputs = []\n",
    "        for x in xs:\n",
    "            x = x.squeeze(0)\n",
    "\n",
    "            # Debugging: Print shape before rim_layer call\n",
    "            print(f\"layer - x shape before rim_layer: {x.shape}\")\n",
    "            print(f\"layer - hs shape before rim_layer: {hs.shape}\")\n",
    "            if cs is not None:\n",
    "                print(f\"layer - cs shape before rim_layer: {cs.shape}\")\n",
    "\n",
    "            hs, cs = rim_layer(x.unsqueeze(1), hs, cs)\n",
    "\n",
    "            # Debugging: Print shape after rim_layer call\n",
    "            print(f\"layer - hs shape after rim_layer: {hs.shape}\")\n",
    "            if cs is not None:\n",
    "                print(f\"layer - cs shape after rim_layer: {cs.shape}\")\n",
    "\n",
    "            outputs.append(hs.view(1, batch_size, -1))\n",
    "\n",
    "        if direction == 1:\n",
    "            outputs.reverse()\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "\n",
    "        # Debugging: Print final outputs shape\n",
    "        print(f\"layer - Final outputs shape: {outputs.shape}\")\n",
    "\n",
    "        if c is not None:\n",
    "            return outputs, hs.view(batch_size, -1), cs.view(batch_size, -1)\n",
    "        else:\n",
    "            return outputs, hs.view(batch_size, -1)\n",
    "\n",
    "    def forward(self, x, h=None, c=None):\n",
    "        \"\"\"\n",
    "        Input: x (seq_len, batch_size, feature_size)\n",
    "               h (num_layers * num_directions, batch_size, hidden_size * num_units)\n",
    "               c (num_layers * num_directions, batch_size, hidden_size * num_units)\n",
    "        Output: outputs (batch_size, seqlen, hidden_size * num_units * num-directions)\n",
    "                h(and c) (num_layer * num_directions, batch_size, hidden_size* num_units)\n",
    "        \"\"\"\n",
    "\n",
    "        # Flatten the input image to match RIM input shape\n",
    "        x = x.view(x.size(0), x.size(1), -1)  # (1, 3, 224*224) -> (1, 1, 3*224*224)\n",
    "\n",
    "        hs = torch.split(h, 1, 0) if h is not None else torch.split(torch.randn(self.n_layers * self.num_directions, x.size(1), self.hidden_size * self.num_units).to(self.device), 1, 0)\n",
    "        hs = list(hs)\n",
    "        cs = None\n",
    "        if self.rnn_cell == 'LSTM':\n",
    "            cs = torch.split(c, 1, 0) if c is not None else torch.split(torch.randn(self.n_layers * self.num_directions, x.size(1), self.hidden_size * self.num_units).to(self.device), 1, 0)\n",
    "            cs = list(cs)\n",
    "        for n in range(self.n_layers):\n",
    "            idx = n * self.num_directions\n",
    "            if cs is not None:\n",
    "                x_fw, hs[idx], cs[idx] = self.layer(self.rimcell[idx], x, hs[idx], cs[idx])\n",
    "            else:\n",
    "                x_fw, hs[idx] = self.layer(self.rimcell[idx], x, hs[idx], c=None)\n",
    "            if self.num_directions == 2:\n",
    "                idx = n * self.num_directions + 1\n",
    "                if cs is not None:\n",
    "                    x_bw, hs[idx], cs[idx] = self.layer(self.rimcell[idx], x, hs[idx], cs[idx], direction=1)\n",
    "                else:\n",
    "                    x_bw, hs[idx] = self.layer(self.rimcell[idx], x, hs[idx], c=None, direction=1)\n",
    "                x = torch.cat((x_fw, x_bw), dim=2)\n",
    "            else:\n",
    "                x = x_fw\n",
    "        hs = torch.stack(hs, dim=0)\n",
    "        if cs is not None:\n",
    "            cs = torch.stack(cs, dim=0)\n",
    "            return x, hs, cs\n",
    "        return x, hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxlU46PFgdSd"
   },
   "source": [
    "## MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1715970681225,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "tNxMhrlyj5IW"
   },
   "outputs": [],
   "source": [
    "# define some image augmentations\n",
    "\n",
    "def vertical_flip(img):\n",
    "    img = TF.to_pil_image(img)\n",
    "    res = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    return TF.to_tensor(res)\n",
    "\n",
    "def brightness(img, factor_range=(0.5, 1.5)):\n",
    "  img = TF.to_pil_image(img)\n",
    "  factor = np.random.uniform(factor_range[0], factor_range[1])\n",
    "  enhancer = ImageEnhance.Brightness(img)\n",
    "  res = enhancer.enhance(factor)\n",
    "  return TF.to_tensor(res)\n",
    "\n",
    "'''\n",
    "def rotation(img, angle_range=(-45, 45)):\n",
    "  angle = np.random.uniform(angle_range[0], angle_range[1])\n",
    "  return img.rotate(angle)\n",
    "'''\n",
    "\n",
    "def color(img, factor_range=(0.5, 1.5)):\n",
    "  img = TF.to_pil_image(img)\n",
    "  factor = np.random.uniform(factor_range[0], factor_range[1])\n",
    "  enhancer = ImageEnhance.Color(img)\n",
    "  res = enhancer.enhance(factor)\n",
    "  return TF.to_tensor(res)\n",
    "\n",
    "def sharpness(img, factor_range=(0.5, 1.5)):\n",
    "  img = TF.to_pil_image(img)\n",
    "  factor = np.random.uniform(factor_range[0], factor_range[1])\n",
    "  enhancer = ImageEnhance.Sharpness(img)\n",
    "  res = enhancer.enhance(factor)\n",
    "  return TF.to_tensor(res)\n",
    "\n",
    "augmentations = [vertical_flip, brightness, color, sharpness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1715970684858,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "9WXWL3Gxh3Cr"
   },
   "outputs": [],
   "source": [
    "# function that applies B augmentations to the original image and returns M+1 images\n",
    "def augment_image_rims(img, augmentations, rims, B=15):\n",
    "    assert len(augmentations) > 0, \"No augmentations provided.\"\n",
    "    images = [img]\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img_tensor = img.unsqueeze(0)  # Add batch dimension\n",
    "    else:\n",
    "        img_tensor = TF.to_tensor(img).unsqueeze(0)  # Convert to tensor and add batch dimension\n",
    "\n",
    "    # Debugging: Print initial shape of img_tensor\n",
    "    print(f\"Initial img_tensor shape: {img_tensor.shape}\")\n",
    "\n",
    "    # Reshape the image tensor to (batch_size, sequence_length, input_size)\n",
    "    batch_size = img_tensor.size(0)\n",
    "    input_size = img_tensor.size(1) * img_tensor.size(2) * img_tensor.size(3)  # Channels * Height * Width\n",
    "    sequence_length = img_tensor.size(2) * img_tensor.size(3)\n",
    "    img_tensor = img_tensor.view(batch_size, sequence_length, input_size // sequence_length)\n",
    "\n",
    "    # Debugging: Print reshaped img_tensor shape\n",
    "    print(f\"Reshaped img_tensor shape: {img_tensor.shape}\")\n",
    "\n",
    "    # Initialize hidden state and cell state for RIMs\n",
    "    h = torch.zeros(rims.n_layers * rims.num_directions, batch_size, rims.hidden_size * rims.num_units).to(rims.device)\n",
    "    c = torch.zeros(rims.n_layers * rims.num_directions, batch_size, rims.hidden_size * rims.num_units).to(rims.device)\n",
    "\n",
    "    # Debugging: Print initial hidden and cell state shapes\n",
    "    print(f\"Initial hidden state shape: {h.shape}\")\n",
    "    print(f\"Initial cell state shape: {c.shape}\")\n",
    "\n",
    "    for i in range(B):\n",
    "        outputs, h, c = rims(img_tensor, h, c)\n",
    "\n",
    "        # Debugging: Print shapes after RIMs processing\n",
    "        print(f\"Iteration {i} - outputs shape: {outputs.shape}\")\n",
    "        print(f\"Iteration {i} - hidden state shape: {h.shape}\")\n",
    "        print(f\"Iteration {i} - cell state shape: {c.shape}\")\n",
    "\n",
    "        attention_weights = torch.softmax(outputs, dim=-1)\n",
    "        hyperparameters = torch.tanh(outputs)  # Assuming hyperparameters are in the range (-1, 1)\n",
    "\n",
    "        # Select augmentation based on attention weights\n",
    "        aug_idx = torch.argmax(attention_weights).item()\n",
    "        augmentation = augmentations[aug_idx]\n",
    "\n",
    "        # Apply augmentation with learned hyperparameters\n",
    "        if augmentation.__name__ in ['brightness', 'color', 'sharpness']:\n",
    "            factor = (hyperparameters[0].item() + 1) / 2  # Scale factor to (0, 1)\n",
    "            augmented_img = augmentation(img, factor_range=(factor, factor))\n",
    "        else:\n",
    "            augmented_img = augmentation(img)\n",
    "\n",
    "        images.append(augmented_img)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1715970687565,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "xc5j-FiVdoBs"
   },
   "outputs": [],
   "source": [
    "# define the cost function used to evaluate the model output\n",
    "def get_cost_function():\n",
    "  cost_function = torch.nn.CrossEntropyLoss()\n",
    "  return cost_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1715970701773,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "pxiafvsgPisv"
   },
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "def get_optimizer(net, lr, wd, momentum):\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1715970703645,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "bhN-AaM_huqQ"
   },
   "outputs": [],
   "source": [
    "# compute the marginal output distribution\n",
    "def marginal_distribution(images, model, transforms, device):\n",
    "  # collect the prediction for every image in input\n",
    "  img_results = []\n",
    "  for img in images:\n",
    "    single_batch = transforms(img).unsqueeze(0).to(device)\n",
    "    prediction = model(single_batch).squeeze(0).softmax(0)\n",
    "    img_results.append(prediction)\n",
    "\n",
    "  # sum all the resulting tensors\n",
    "  sum_results = torch.sum(torch.stack(img_results), dim=0).to(device)\n",
    "  # divide each element by B to obtain the marginal output distribution\n",
    "  num_images = len(images)\n",
    "  res = torch.div(sum_results, num_images).to(device)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1715971147154,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "lq-B2QHFufkB"
   },
   "outputs": [],
   "source": [
    "# compute the marginal cross entropy\n",
    "def marginal_cross_entropy(marginal_dist, labels, cost_function):\n",
    "  entropy = 0.0\n",
    "  # sum all entropies for the different labels since I don't know the real one\n",
    "  for label in labels:\n",
    "    entropy += cost_function(marginal_dist, label)\n",
    "  return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1715971150673,
     "user": {
      "displayName": "Edoardo Cecchinato",
      "userId": "16439300506635722937"
     },
     "user_tz": -120
    },
    "id": "_cmtwAFRFCoW",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 7500 images.\n",
      "The dataset contains 200 labels.\n",
      "Input dimension: 150528\n",
      "RIMs model initialized with input_dim=150528, hidden_dim=128, num_units=4, k=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial img_tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Reshaped img_tensor shape: torch.Size([1, 50176, 3])\n",
      "Initial hidden state shape: torch.Size([2, 1, 512])\n",
      "Initial cell state shape: torch.Size([2, 1, 512])\n",
      "layer - Initial x shape: torch.Size([1, 50176, 3])\n",
      "layer - Initial h shape: torch.Size([1, 1, 512])\n",
      "layer - Initial c shape: torch.Size([1, 1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[50176, 4, -1]' is invalid for input of size 512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 94\u001b[0m\n\u001b[1;32m     90\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m test_with_rims(model, test_loader, num_augmentations, cost_function, optimizer, preprocess, device, rims)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m \u001b[43mmain_with_rims\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet_MEMO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 90\u001b[0m, in \u001b[0;36mmain_with_rims\u001b[0;34m(run_name, batch_size, device, learning_rate, weight_decay, momentum, num_augmentations)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRIMs model initialized with input_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, hidden_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_units=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_units\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest_with_rims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 34\u001b[0m, in \u001b[0;36mtest_with_rims\u001b[0;34m(model, data_loader, B, cost_function, optimizer, transforms, device, rims)\u001b[0m\n\u001b[1;32m     32\u001b[0m intermediate_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m---> 34\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mttr_MEMO_with_rims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     intermediate_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(intermediate_outputs)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m, in \u001b[0;36mttr_MEMO_with_rims\u001b[0;34m(model, test_sample, labels, B, cost_function, optimizer, transforms, device, rims)\u001b[0m\n\u001b[1;32m      2\u001b[0m original_params \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m----> 5\u001b[0m     augmented_images \u001b[38;5;241m=\u001b[39m \u001b[43maugment_image_rims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     marginal_dist \u001b[38;5;241m=\u001b[39m marginal_distribution(augmented_images, model, transforms, device)\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m marginal_cross_entropy(marginal_dist, labels, cost_function)\n",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m, in \u001b[0;36maugment_image_rims\u001b[0;34m(img, augmentations, rims, B)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial cell state shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B):\n\u001b[0;32m---> 31\u001b[0m     outputs, h, c \u001b[38;5;241m=\u001b[39m \u001b[43mrims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Debugging: Print shapes after RIMs processing\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - outputs shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 311\u001b[0m, in \u001b[0;36mRIM.forward\u001b[0;34m(self, x, h, c)\u001b[0m\n\u001b[1;32m    309\u001b[0m idx \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_directions\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     x_fw, hs[idx], cs[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrimcell\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     x_fw, hs[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrimcell[idx], x, hs[idx], c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 247\u001b[0m, in \u001b[0;36mRIM.layer\u001b[0;34m(self, rim_layer, x, h, c, direction)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m direction \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    245\u001b[0m     xs\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m--> 247\u001b[0m hs \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Debugging: Print reshaped hs shape\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer - Reshaped hs shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[50176, 4, -1]' is invalid for input of size 512"
     ]
    }
   ],
   "source": [
    "def ttr_MEMO_with_rims(model, test_sample, labels, B, cost_function, optimizer, transforms, device, rims):\n",
    "    original_params = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        augmented_images = augment_image_rims(test_sample, augmentations, rims, B)\n",
    "        marginal_dist = marginal_distribution(augmented_images, model, transforms, device)\n",
    "        \n",
    "        loss = marginal_cross_entropy(marginal_dist, labels, cost_function)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    test_sample = transforms(test_sample).unsqueeze(0).to(device)\n",
    "    output = model(test_sample).squeeze(0).softmax(0)\n",
    "    model.load_state_dict(original_params)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def test_with_rims(model, data_loader, B, cost_function, optimizer, transforms, device, rims):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Testing\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            batch_size = inputs.size(0)\n",
    "            intermediate_outputs = []\n",
    "            for input in inputs:\n",
    "                output = ttr_MEMO_with_rims(model, input, targets, B, cost_function, optimizer, transforms, device, rims)\n",
    "                intermediate_outputs.append(output)\n",
    "\n",
    "            outputs = torch.stack(intermediate_outputs).to(device)\n",
    "            loss = cost_function(outputs, targets)\n",
    "\n",
    "            samples += inputs.shape[0]\n",
    "            cumulative_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100\n",
    "\n",
    "def main_with_rims(\n",
    "    run_name,\n",
    "    batch_size=32,\n",
    "    device=\"cuda\",\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.000001,\n",
    "    momentum=0.9,\n",
    "    num_augmentations=15\n",
    "):\n",
    "    device = torch.device(device)\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights).to(device)\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Initialize the test dataloader\n",
    "    test_loader, _ = get_data(batch_size, data_folder, preprocess)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = get_optimizer(model, learning_rate, weight_decay, momentum)\n",
    "\n",
    "    # Initialize the cost function\n",
    "    cost_function = get_cost_function()\n",
    "\n",
    "    # Get a sample image to determine the input dimension\n",
    "    sample_img, _ = next(iter(test_loader))\n",
    "    sample_img = sample_img[0].unsqueeze(0)  # Take one sample and add batch dimension\n",
    "    sample_img = preprocess(sample_img)\n",
    "    input_dim = sample_img.size(1) * sample_img.size(2) * sample_img.size(3)  # Channels * Height * Width\n",
    "\n",
    "    # Debugging: Print input_dim\n",
    "    print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "    hidden_dim = 128\n",
    "    num_units = 4\n",
    "    k = 2\n",
    "\n",
    "    # Initialize RIMs\n",
    "    rims = RIM(device, input_dim, hidden_dim, num_units, k, rnn_cell='LSTM', n_layers=2, bidirectional=False).to(device)\n",
    "\n",
    "    # Debugging: Print RIMs initial state\n",
    "    print(f\"RIMs model initialized with input_dim={input_dim}, hidden_dim={hidden_dim}, num_units={num_units}, k={k}\")\n",
    "\n",
    "    # Run the test\n",
    "    test_loss, test_accuracy = test_with_rims(model, test_loader, num_augmentations, cost_function, optimizer, preprocess, device, rims)\n",
    "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
    "\n",
    "\n",
    "main_with_rims(\"resnet_MEMO\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
