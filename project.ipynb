{"cells":[{"cell_type":"markdown","metadata":{"id":"PDYnDRjPfNF_"},"source":["# DL Project 2023/24"]},{"cell_type":"markdown","metadata":{"id":"ll5uAwzhfYHn"},"source":["## Introduction\n","\n","Description of the method choosen and the work done"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":19732,"status":"ok","timestamp":1715970600487,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"Lw7k2mxRfE1D"},"outputs":[],"source":["# import modules\n","import torch\n","import torchvision\n","from torchvision.models import resnet50, ResNet50_Weights\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37897,"status":"ok","timestamp":1715970642796,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"qQnIh3lo3VAS","outputId":"94b3fb3e-e93d-4bf2-eceb-79b231353554"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"MqX-jwMHgZ3G"},"source":["## Reading Data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21703,"status":"ok","timestamp":1715970667457,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"4h7Y7SSrgc7y","outputId":"bd874e65-9065-46ec-947e-8a4ae09e067e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Compress file doesn't exist.\n"]}],"source":["import tarfile\n","import os\n","import shutil\n","import re\n","\n","tar_file = \"./drive/MyDrive/DL_project/imagenet-a.tar\"\n","data_folder = \"imagenet-a\"\n","\n","# function to untar the dataset and store it in a new folder\n","def extract_dataset(compress_file, destination_folder):\n","  # function to change dir names to their words description\n","  def change_folders_names(readme_file, dataset_root):\n","    with open(readme_file, 'r') as f:\n","        lines = f.readlines()\n","        for line in lines:\n","            # Match lines containing WordNet IDs and descriptions\n","            match = re.match(r'n\\d+ (.+)', line)\n","            if match:\n","                # Split the line into WordNet ID and description\n","                parts = match.group(0).split()\n","                wordnet_id = parts[0]\n","                description = ' '.join(parts[1:])\n","                os.rename(os.path.join(dataset_root, wordnet_id),\n","                            os.path.join(dataset_root, description))\n","\n","  if not os.path.exists(compress_file):\n","    print(\"Compress file doesn't exist.\")\n","    return\n","\n","  if os.path.exists(destination_folder):\n","    # remove the folder if already exists one\n","    shutil.rmtree(destination_folder)\n","\n","  # extract content from the .tar file\n","  with tarfile.open(compress_file, 'r') as tar_ref:\n","    tar_ref.extractall(\"./\")\n","  print(\"All the data is extracted.\")\n","\n","  change_folders_names(destination_folder+\"/README.txt\", destination_folder)\n","\n","extract_dataset(tar_file, data_folder)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":592,"status":"ok","timestamp":1715970670636,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"rzBAWU06L_Mm","outputId":"2a005eca-33f2-45bb-ea03-a7427ee7fa99"},"outputs":[{"name":"stdout","output_type":"stream","text":["['teddy bear', 'Persian cat', 'rocking chair', 'agama', 'feather boa', 'tarantula', 'German Shepherd Dog', 'couch', 'box turtle', 'pug', 'snail', 'American robin', 'tank', 'baseball player', 'volleyball', 'hummingbird', 'chain', 'cliff', 'lynx', 'mitten', 'newt', 'breastplate', 'sleeping bag', 'snowplow', 'parachute', 'starfish', 'small white', 'junco', 'sea lion', 'hot dog', 'cucumber', 'sundial', 'suspension bridge', 'parking meter', 'acorn', 'broccoli', 'kimono', 'cheeseburger', 'submarine', 'mushroom', 'pelican', 'wine bottle', 'digital clock', 'oystercatcher', 'reel', 'fly', 'hermit crab', 'washing machine', 'piggy bank', 'drumstick', 'acoustic guitar', 'barn', 'hockey puck', 'accordion', 'flamingo', 'forklift', 'cello', 'lorikeet', 'maraca', 'lion', 'schooner', 'bald eagle', 'cottontail rabbit', 'goblet', 'tricycle', 'corn', 'great egret', 'envelope', 'manhole cover', 'duck', 'quill', 'goldfinch', 'garter snake', 'bow', 'American black bear', 'skunk', 'fountain', 'porcupine', 'spatula', 'bell pepper', \"jack-o'-lantern\", 'obelisk', 'bison', 'broom', 'rotary dial telephone', 'ant', 'water tower', 'unicycle', 'syringe', 'bikini', 'pufferfish', 'koala', 'viaduct', 'gossamer-winged butterfly', 'armadillo', 'Rottweiler', 'stingray', 'saxophone', 'American alligator', 'castle', 'billiard table', 'snowmobile', 'white-headed capuchin', 'volcano', 'garbage truck', 'go-kart', 'chameleon', 'balance beam', 'dragonfly', 'salt shaker', 'basketball', 'doormat', 'lighthouse', 'fox squirrel', 'pretzel', 'dumbbell', 'marimba', 'sewing machine', 'custard apple', 'soap dispenser', 'candle', 'leafhopper', 'monarch butterfly', 'Golden Retriever', 'ladybug', 'cradle', 'scorpion', 'steam locomotive', 'toucan', 'vulture', 'African bush elephant', 'shipwreck', 'jellyfish', 'stethoscope', 'grasshopper', 'nail', 'rapeseed', 'flatworm', 'baboon', 'centipede', 'shovel', 'sea anemone', 'red fox', 'bubble', 'mantis', 'mask', 'airliner', 'lighter', 'American bullfrog', 'README.txt', 'school bus', 'mosque', 'wheelbarrow', 'limousine', 'Chihuahua', 'jay', 'torch', 'stick insect', 'marmot', 'balloon', 'flagpole', 'Christmas stocking', 'ocarina', 'banjo', 'pomegranate', 'rhinoceros beetle', 'organ', 'academic gown', 'carbonara', 'bow tie', 'cowboy boot', 'jeep', 'ambulance', 'goose', 'banana', 'hair dryer', 'racket', 'green iguana', 'lemon', 'bee', 'cockroach', 'clothes iron', 'crayfish', 'revolver', 'weevil', 'sandal', 'rugby ball', 'guacamole', 'apron', 'canoe', \"yellow lady's slipper\", 'grand piano', 'spider web', 'toaster', 'umbrella', 'harvestman', 'chest', 'mongoose', 'beaker', 'golf cart', 'sulphur-crested cockatoo']\n"]},{"data":{"text/plain":["201"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["ids_list = os.listdir(data_folder)\n","print(ids_list)\n","len(ids_list) # 200 folders + 1 readme"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1715970673171,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"eul04CxP3VaH"},"outputs":[],"source":["from PIL import Image\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","\n","# imagenet-a has only 200 classes, but the pretrained model outputs 1000 labels distribution\n","# this is a mapping from imagenet-a to imagenet\n","thousand_k_to_200 = {0: -1, 1: -1, 2: -1, 3: -1, 4: -1, 5: -1, 6: 0, 7: -1, 8: -1, 9: -1, 10: -1, 11: 1, 12: -1, 13: 2, 14: -1, 15: 3, 16: -1, 17: 4, 18: -1, 19: -1, 20: -1, 21: -1, 22: 5, 23: 6, 24: -1, 25: -1, 26: -1, 27: 7, 28: -1, 29: -1, 30: 8, 31: -1, 32: -1, 33: -1, 34: -1, 35: -1, 36: -1, 37: 9, 38: -1, 39: 10, 40: -1, 41: -1, 42: 11, 43: -1, 44: -1, 45: -1, 46: -1, 47: 12, 48: -1, 49: -1, 50: 13, 51: -1, 52: -1, 53: -1, 54: -1, 55: -1, 56: -1, 57: 14, 58: -1, 59: -1, 60: -1, 61: -1, 62: -1, 63: -1, 64: -1, 65: -1, 66: -1, 67: -1, 68: -1, 69: -1, 70: 15, 71: 16, 72: -1, 73: -1, 74: -1, 75: -1, 76: 17, 77: -1, 78: -1, 79: 18, 80: -1, 81: -1, 82: -1, 83: -1, 84: -1, 85: -1, 86: -1, 87: -1, 88: -1, 89: 19, 90: 20, 91: -1, 92: -1, 93: -1, 94: 21, 95: -1, 96: 22, 97: 23, 98: -1, 99: 24, 100: -1, 101: -1, 102: -1, 103: -1, 104: -1, 105: 25, 106: -1, 107: 26, 108: 27, 109: -1, 110: 28, 111: -1, 112: -1, 113: 29, 114: -1, 115: -1, 116: -1, 117: -1, 118: -1, 119: -1, 120: -1, 121: -1, 122: -1, 123: -1, 124: 30, 125: 31, 126: -1, 127: -1, 128: -1, 129: -1, 130: 32, 131: -1, 132: 33, 133: -1, 134: -1, 135: -1, 136: -1, 137: -1, 138: -1, 139: -1, 140: -1, 141: -1, 142: -1, 143: 34, 144: 35, 145: -1, 146: -1, 147: -1, 148: -1, 149: -1, 150: 36, 151: 37, 152: -1, 153: -1, 154: -1, 155: -1, 156: -1, 157: -1, 158: -1, 159: -1, 160: -1, 161: -1, 162: -1, 163: -1, 164: -1, 165: -1, 166: -1, 167: -1, 168: -1, 169: -1, 170: -1, 171: -1, 172: -1, 173: -1, 174: -1, 175: -1, 176: -1, 177: -1, 178: -1, 179: -1, 180: -1, 181: -1, 182: -1, 183: -1, 184: -1, 185: -1, 186: -1, 187: -1, 188: -1, 189: -1, 190: -1, 191: -1, 192: -1, 193: -1, 194: -1, 195: -1, 196: -1, 197: -1, 198: -1, 199: -1, 200: -1, 201: -1, 202: -1, 203: -1, 204: -1, 205: -1, 206: -1, 207: 38, 208: -1, 209: -1, 210: -1, 211: -1, 212: -1, 213: -1, 214: -1, 215: -1, 216: -1, 217: -1, 218: -1, 219: -1, 220: -1, 221: -1, 222: -1, 223: -1, 224: -1, 225: -1, 226: -1, 227: -1, 228: -1, 229: -1, 230: -1, 231: -1, 232: -1, 233: -1, 234: 39, 235: 40, 236: -1, 237: -1, 238: -1, 239: -1, 240: -1, 241: -1, 242: -1, 243: -1, 244: -1, 245: -1, 246: -1, 247: -1, 248: -1, 249: -1, 250: -1, 251: -1, 252: -1, 253: -1, 254: 41, 255: -1, 256: -1, 257: -1, 258: -1, 259: -1, 260: -1, 261: -1, 262: -1, 263: -1, 264: -1, 265: -1, 266: -1, 267: -1, 268: -1, 269: -1, 270: -1, 271: -1, 272: -1, 273: -1, 274: -1, 275: -1, 276: -1, 277: 42, 278: -1, 279: -1, 280: -1, 281: -1, 282: -1, 283: 43, 284: -1, 285: -1, 286: -1, 287: 44, 288: -1, 289: -1, 290: -1, 291: 45, 292: -1, 293: -1, 294: -1, 295: 46, 296: -1, 297: -1, 298: 47, 299: -1, 300: -1, 301: 48, 302: -1, 303: -1, 304: -1, 305: -1, 306: 49, 307: 50, 308: 51, 309: 52, 310: 53, 311: 54, 312: -1, 313: 55, 314: 56, 315: 57, 316: -1, 317: 58, 318: -1, 319: 59, 320: -1, 321: -1, 322: -1, 323: 60, 324: 61, 325: -1, 326: 62, 327: 63, 328: -1, 329: -1, 330: 64, 331: -1, 332: -1, 333: -1, 334: 65, 335: 66, 336: 67, 337: -1, 338: -1, 339: -1, 340: -1, 341: -1, 342: -1, 343: -1, 344: -1, 345: -1, 346: -1, 347: 68, 348: -1, 349: -1, 350: -1, 351: -1, 352: -1, 353: -1, 354: -1, 355: -1, 356: -1, 357: -1, 358: -1, 359: -1, 360: -1, 361: 69, 362: -1, 363: 70, 364: -1, 365: -1, 366: -1, 367: -1, 368: -1, 369: -1, 370: -1, 371: -1, 372: 71, 373: -1, 374: -1, 375: -1, 376: -1, 377: -1, 378: 72, 379: -1, 380: -1, 381: -1, 382: -1, 383: -1, 384: -1, 385: -1, 386: 73, 387: -1, 388: -1, 389: -1, 390: -1, 391: -1, 392: -1, 393: -1, 394: -1, 395: -1, 396: -1, 397: 74, 398: -1, 399: -1, 400: 75, 401: 76, 402: 77, 403: -1, 404: 78, 405: -1, 406: -1, 407: 79, 408: -1, 409: -1, 410: -1, 411: 80, 412: -1, 413: -1, 414: -1, 415: -1, 416: 81, 417: 82, 418: -1, 419: -1, 420: 83, 421: -1, 422: -1, 423: -1, 424: -1, 425: 84, 426: -1, 427: -1, 428: 85, 429: -1, 430: 86, 431: -1, 432: -1, 433: -1, 434: -1, 435: -1, 436: -1, 437: 87, 438: 88, 439: -1, 440: -1, 441: -1, 442: -1, 443: -1, 444: -1, 445: 89, 446: -1, 447: -1, 448: -1, 449: -1, 450: -1, 451: -1, 452: -1, 453: -1, 454: -1, 455: -1, 456: 90, 457: 91, 458: -1, 459: -1, 460: -1, 461: 92, 462: 93, 463: -1, 464: -1, 465: -1, 466: -1, 467: -1, 468: -1, 469: -1, 470: 94, 471: -1, 472: 95, 473: -1, 474: -1, 475: -1, 476: -1, 477: -1, 478: -1, 479: -1, 480: -1, 481: -1, 482: -1, 483: 96, 484: -1, 485: -1, 486: 97, 487: -1, 488: 98, 489: -1, 490: -1, 491: -1, 492: 99, 493: -1, 494: -1, 495: -1, 496: 100, 497: -1, 498: -1, 499: -1, 500: -1, 501: -1, 502: -1, 503: -1, 504: -1, 505: -1, 506: -1, 507: -1, 508: -1, 509: -1, 510: -1, 511: -1, 512: -1, 513: -1, 514: 101, 515: -1, 516: 102, 517: -1, 518: -1, 519: -1, 520: -1, 521: -1, 522: -1, 523: -1, 524: -1, 525: -1, 526: -1, 527: -1, 528: 103, 529: -1, 530: 104, 531: -1, 532: -1, 533: -1, 534: -1, 535: -1, 536: -1, 537: -1, 538: -1, 539: 105, 540: -1, 541: -1, 542: 106, 543: 107, 544: -1, 545: -1, 546: -1, 547: -1, 548: -1, 549: 108, 550: -1, 551: -1, 552: 109, 553: -1, 554: -1, 555: -1, 556: -1, 557: 110, 558: -1, 559: -1, 560: -1, 561: 111, 562: 112, 563: -1, 564: -1, 565: -1, 566: -1, 567: -1, 568: -1, 569: 113, 570: -1, 571: -1, 572: 114, 573: 115, 574: -1, 575: 116, 576: -1, 577: -1, 578: -1, 579: 117, 580: -1, 581: -1, 582: -1, 583: -1, 584: -1, 585: -1, 586: -1, 587: -1, 588: -1, 589: 118, 590: -1, 591: -1, 592: -1, 593: -1, 594: -1, 595: -1, 596: -1, 597: -1, 598: -1, 599: -1, 600: -1, 601: -1, 602: -1, 603: -1, 604: -1, 605: -1, 606: 119, 607: 120, 608: -1, 609: 121, 610: -1, 611: -1, 612: -1, 613: -1, 614: 122, 615: -1, 616: -1, 617: -1, 618: -1, 619: -1, 620: -1, 621: -1, 622: -1, 623: -1, 624: -1, 625: -1, 626: 123, 627: 124, 628: -1, 629: -1, 630: -1, 631: -1, 632: -1, 633: -1, 634: -1, 635: -1, 636: -1, 637: -1, 638: -1, 639: -1, 640: 125, 641: 126, 642: 127, 643: 128, 644: -1, 645: -1, 646: -1, 647: -1, 648: -1, 649: -1, 650: -1, 651: -1, 652: -1, 653: -1, 654: -1, 655: -1, 656: -1, 657: -1, 658: 129, 659: -1, 660: -1, 661: -1, 662: -1, 663: -1, 664: -1, 665: -1, 666: -1, 667: -1, 668: 130, 669: -1, 670: -1, 671: -1, 672: -1, 673: -1, 674: -1, 675: -1, 676: -1, 677: 131, 678: -1, 679: -1, 680: -1, 681: -1, 682: 132, 683: -1, 684: 133, 685: -1, 686: -1, 687: 134, 688: -1, 689: -1, 690: -1, 691: -1, 692: -1, 693: -1, 694: -1, 695: -1, 696: -1, 697: -1, 698: -1, 699: -1, 700: -1, 701: 135, 702: -1, 703: -1, 704: 136, 705: -1, 706: -1, 707: -1, 708: -1, 709: -1, 710: -1, 711: -1, 712: -1, 713: -1, 714: -1, 715: -1, 716: -1, 717: -1, 718: -1, 719: 137, 720: -1, 721: -1, 722: -1, 723: -1, 724: -1, 725: -1, 726: -1, 727: -1, 728: -1, 729: -1, 730: -1, 731: -1, 732: -1, 733: -1, 734: -1, 735: -1, 736: 138, 737: -1, 738: -1, 739: -1, 740: -1, 741: -1, 742: -1, 743: -1, 744: -1, 745: -1, 746: 139, 747: -1, 748: -1, 749: 140, 750: -1, 751: -1, 752: 141, 753: -1, 754: -1, 755: -1, 756: -1, 757: -1, 758: 142, 759: -1, 760: -1, 761: -1, 762: -1, 763: 143, 764: -1, 765: 144, 766: -1, 767: -1, 768: 145, 769: -1, 770: -1, 771: -1, 772: -1, 773: 146, 774: 147, 775: -1, 776: 148, 777: -1, 778: -1, 779: 149, 780: 150, 781: -1, 782: -1, 783: -1, 784: -1, 785: -1, 786: 151, 787: -1, 788: -1, 789: -1, 790: -1, 791: -1, 792: 152, 793: -1, 794: -1, 795: -1, 796: -1, 797: 153, 798: -1, 799: -1, 800: -1, 801: -1, 802: 154, 803: 155, 804: 156, 805: -1, 806: -1, 807: -1, 808: -1, 809: -1, 810: -1, 811: -1, 812: -1, 813: 157, 814: -1, 815: 158, 816: -1, 817: -1, 818: -1, 819: -1, 820: 159, 821: -1, 822: -1, 823: 160, 824: -1, 825: -1, 826: -1, 827: -1, 828: -1, 829: -1, 830: -1, 831: 161, 832: -1, 833: 162, 834: -1, 835: 163, 836: -1, 837: -1, 838: -1, 839: 164, 840: -1, 841: -1, 842: -1, 843: -1, 844: -1, 845: 165, 846: -1, 847: 166, 848: -1, 849: -1, 850: 167, 851: -1, 852: -1, 853: -1, 854: -1, 855: -1, 856: -1, 857: -1, 858: -1, 859: 168, 860: -1, 861: -1, 862: 169, 863: -1, 864: -1, 865: -1, 866: -1, 867: -1, 868: -1, 869: -1, 870: 170, 871: -1, 872: -1, 873: -1, 874: -1, 875: -1, 876: -1, 877: -1, 878: -1, 879: 171, 880: 172, 881: -1, 882: -1, 883: -1, 884: -1, 885: -1, 886: -1, 887: -1, 888: 173, 889: -1, 890: 174, 891: -1, 892: -1, 893: -1, 894: -1, 895: -1, 896: -1, 897: 175, 898: -1, 899: -1, 900: 176, 901: -1, 902: -1, 903: -1, 904: -1, 905: -1, 906: -1, 907: 177, 908: -1, 909: -1, 910: -1, 911: -1, 912: -1, 913: 178, 914: -1, 915: -1, 916: -1, 917: -1, 918: -1, 919: -1, 920: -1, 921: -1, 922: -1, 923: -1, 924: 179, 925: -1, 926: -1, 927: -1, 928: -1, 929: -1, 930: -1, 931: -1, 932: 180, 933: 181, 934: 182, 935: -1, 936: -1, 937: 183, 938: -1, 939: -1, 940: -1, 941: -1, 942: -1, 943: 184, 944: -1, 945: 185, 946: -1, 947: 186, 948: -1, 949: -1, 950: -1, 951: 187, 952: -1, 953: -1, 954: 188, 955: -1, 956: 189, 957: 190, 958: -1, 959: 191, 960: -1, 961: -1, 962: -1, 963: -1, 964: -1, 965: -1, 966: -1, 967: -1, 968: -1, 969: -1, 970: -1, 971: 192, 972: 193, 973: -1, 974: -1, 975: -1, 976: -1, 977: -1, 978: -1, 979: -1, 980: 194, 981: 195, 982: -1, 983: -1, 984: 196, 985: -1, 986: 197, 987: 198, 988: 199, 989: -1, 990: -1, 991: -1, 992: -1, 993: -1, 994: -1, 995: -1, 996: -1, 997: -1, 998: -1, 999: -1}\n","indices_in_1k = [k for k in thousand_k_to_200 if thousand_k_to_200[k] != -1]\n","\n","# function that returns a DataLoader for the dataset\n","def get_data(batch_size, dataset_path, transform):\n","  data = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n","\n","  class_labels = data.classes\n","  print(f\"The dataset contains {len(data)} images.\")\n","  print(f\"The dataset contains {len(class_labels)} labels.\")\n","\n","  test_loader = torch.utils.data.DataLoader(data, batch_size, shuffle=False, num_workers=8)\n","\n","  return test_loader, class_labels"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":470,"status":"ok","timestamp":1715970676875,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"HHAElKCP7mMv"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torchvision.transforms.functional as TF\n","\n","# function to display images from the DataLoader\n","def show_images(dataloader, num_images=5):\n","  # get a batch of data\n","  data_iter = iter(dataloader)\n","  images, labels = next(data_iter)\n","\n","  # convert images to numpy array\n","  images = images.numpy()\n","\n","  # display images\n","  fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n","  for i in range(num_images):\n","      image = np.transpose(images[i], (1, 2, 0))  # move channels in last position\n","      image = np.clip(image, 0, 1)\n","      axes[i].imshow(image)\n","      axes[i].axis('off')\n","      axes[i].set_title(dataloader.dataset.classes[labels[i]])\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"VxlU46PFgdSd"},"source":["## MEMO"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":518,"status":"ok","timestamp":1715970681225,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"tNxMhrlyj5IW"},"outputs":[],"source":["from PIL import ImageOps, ImageEnhance\n","\n","# define some image augmentations\n","\n","def vertical_flip(img):\n","    img = TF.to_pil_image(img)\n","    res = img.transpose(Image.FLIP_TOP_BOTTOM)\n","    return TF.to_tensor(res)\n","\n","def brightness(img, factor_range=(0.5, 1.5)):\n","  img = TF.to_pil_image(img)\n","  factor = np.random.uniform(factor_range[0], factor_range[1])\n","  enhancer = ImageEnhance.Brightness(img)\n","  res = enhancer.enhance(factor)\n","  return TF.to_tensor(res)\n","\n","'''\n","def rotation(img, angle_range=(-45, 45)):\n","  angle = np.random.uniform(angle_range[0], angle_range[1])\n","  return img.rotate(angle)\n","'''\n","\n","def color(img, factor_range=(0.5, 1.5)):\n","  img = TF.to_pil_image(img)\n","  factor = np.random.uniform(factor_range[0], factor_range[1])\n","  enhancer = ImageEnhance.Color(img)\n","  res = enhancer.enhance(factor)\n","  return TF.to_tensor(res)\n","\n","def sharpness(img, factor_range=(0.5, 1.5)):\n","  img = TF.to_pil_image(img)\n","  factor = np.random.uniform(factor_range[0], factor_range[1])\n","  enhancer = ImageEnhance.Sharpness(img)\n","  res = enhancer.enhance(factor)\n","  return TF.to_tensor(res)\n","\n","augmentations = [vertical_flip, brightness, color, sharpness]"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715970684858,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"9WXWL3Gxh3Cr"},"outputs":[],"source":["import random\n","\n","# functon that apply B augmentations to the original image and return M+1 images\n","def augment_image(img, augmentations, B=15):\n","  assert len(augmentations) > 0, \"There are not augmentations provided.\"\n","\n","  images = [img]\n","  for _ in range(B):\n","    # randomly choose an augmentation in the augmentation functions\n","    index = random.randrange(0, len(augmentations))\n","    augmentation = augmentations[index]\n","    # apply the augmentation to the original image\n","    augmented_img = augmentation(img)\n","    # add the augmented image to the list of images I want to evaluate\n","    images.append(augmented_img)\n","  return images"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":470,"status":"ok","timestamp":1715970687565,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"xc5j-FiVdoBs"},"outputs":[],"source":["# define the cost function used to evaluate the model output\n","def get_cost_function():\n","  cost_function = torch.nn.CrossEntropyLoss()\n","  return cost_function"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":556,"status":"ok","timestamp":1715970701773,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"pxiafvsgPisv"},"outputs":[],"source":["# define the optimizer\n","def get_optimizer(net, lr, wd, momentum):\n","    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n","    return optimizer"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715970703645,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"bhN-AaM_huqQ"},"outputs":[],"source":["# compute the marginal output distribution\n","def marginal_distribution(images, model, transforms, device):\n","  # collect the prediction for every image in input\n","  img_results = []\n","  for img in images:\n","    single_batch = transforms(img).unsqueeze(0).to(device)\n","    prediction = model(single_batch).squeeze(0)[indices_in_1k].softmax(0)\n","    img_results.append(prediction)\n","\n","  # sum all the resulting tensors\n","  sum_results = torch.sum(torch.stack(img_results), dim=0).to(device)\n","  # divide each element by B to obtain the marginal output distribution\n","  num_images = len(images)\n","  res = torch.div(sum_results, num_images).to(device)\n","  return res"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":577,"status":"ok","timestamp":1715971147154,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"lq-B2QHFufkB"},"outputs":[],"source":["# compute the marginal cross entropy\n","def marginal_cross_entropy(marginal_dist, labels, cost_function):\n","  entropy = 0.0\n","  # sum all entropies for the different labels since I don't know the real one\n","  for label in labels:\n","    entropy += cost_function(marginal_dist, label)\n","  return entropy"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":527,"status":"ok","timestamp":1715971150673,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"_cmtwAFRFCoW"},"outputs":[],"source":["import copy\n","\n","# test time robustness via MEMO algorithm\n","def ttr_MEMO(model, test_sample, labels, B, cost_function, optimizer, transforms, device):\n","  # save the original model weights\n","  original_params = copy.deepcopy(model.state_dict())\n","\n","  with torch.enable_grad():\n","    # get the B + 1 images\n","    augmented_images = augment_image(test_sample, augmentations, B)\n","\n","    # get the marginal output distribution\n","    marginal_dist = marginal_distribution(augmented_images, model, transforms, device)\n","\n","    # update the model weights\n","    loss = marginal_cross_entropy(marginal_dist, labels, cost_function)\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","  test_sample = transforms(test_sample).unsqueeze(0).to(device)\n","  output = model(test_sample).squeeze(0)[indices_in_1k].softmax(0)\n","\n","  # reapply original weights to the model\n","  model.load_state_dict(original_params)\n","\n","  return output"]},{"cell_type":"markdown","metadata":{"id":"98wdJeghGZsv"},"source":["## Test Procedure"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715970785640,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"BXSBVg2bGdlZ"},"outputs":[],"source":["def test(model, data_loader, B, cost_function, optimizer, transforms, device=\"cuda\"):\n","  samples = 0.0\n","  cumulative_loss = 0.0\n","  cumulative_accuracy = 0.0\n","\n","  # set the network to evaluation mode\n","  model.eval()\n","\n","  # disable gradient computation for testing mode\n","  with torch.no_grad():\n","    # iterate over the test set\n","    for batch_idx, (inputs, targets) in enumerate(data_loader):\n","      # Load data into GPU\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      # forward pass\n","      batch_size = inputs.size(0)\n","      num_labels = 1000 # 1000 is the ImageNet number of labels\n","      empty_tensor = torch.empty(num_labels).to(device)\n","\n","      # apply MEMO to each test point in the batch\n","      intermediate_outputs = []\n","      for input in inputs:\n","        output = ttr_MEMO(model, input, targets, B, cost_function, optimizer, transforms, device)\n","        intermediate_outputs.append(output)\n","\n","      outputs = torch.stack(intermediate_outputs).to(device)\n","\n","      # outputs_no_MEMO = model(inputs)\n","\n","      # loss computation\n","      loss = cost_function(outputs, targets)\n","\n","      # fetch prediction and loss value\n","      samples+=inputs.shape[0]\n","      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n","      _, predicted = outputs.max(1) # get the indeces of the predicted classes\n","\n","      # compute accuracy\n","      cumulative_accuracy += predicted.eq(targets).sum().item()\n","      print(f\"batch {batch_idx} -- Test loss {(cumulative_loss / samples):.5f}, Test accuracy {(cumulative_accuracy / samples * 100):.5f}\")\n","\n","\n","  return cumulative_loss / samples, cumulative_accuracy / samples * 100"]},{"cell_type":"markdown","metadata":{"id":"-mjNvK8WYlEk"},"source":["## Put all together"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":571,"status":"ok","timestamp":1715971213798,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"GWwZuurhYpza"},"outputs":[],"source":["def main(\n","    run_name,\n","    batch_size = 32,\n","    device = \"cuda\",\n","    learning_rate=0.001,\n","    weight_decay=0.000001,\n","    momentum=0.9,\n","    num_augmentations = 15\n","):\n","  # writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n","  device = device\n","\n","  # itialize the ResNet model\n","  weights = ResNet50_Weights.DEFAULT\n","  model = resnet50(weights=weights).to(device)\n","\n","  # initialize the inference transforms\n","  preprocess = weights.transforms()\n","  preprocess\n","\n","  # initialize the test dataloader\n","  test_loader, _ = get_data(batch_size, data_folder, preprocess)\n","\n","  # initialize the optimizer\n","  optimizer = get_optimizer(model, learning_rate, weight_decay, momentum)\n","\n","  # initialize the cost function\n","  cost_function = get_cost_function()\n","\n","  test_loss, test_accuracy = test(model, test_loader, num_augmentations, cost_function, optimizer, preprocess, device)\n","  print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3543859,"status":"ok","timestamp":1715974761520,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"},"user_tz":-120},"id":"lCWTd6ZxHqiE","outputId":"7fd8d829-23d9-4bee-d038-0205844497b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["The dataset contains 7500 images.\n","The dataset contains 200 labels.\n","batch 0 -- Test loss 0.16388, Test accuracy 6.25000\n","batch 1 -- Test loss 0.16486, Test accuracy 3.12500\n","batch 2 -- Test loss 0.16518, Test accuracy 2.08333\n","batch 3 -- Test loss 0.16534, Test accuracy 1.56250\n","batch 4 -- Test loss 0.16544, Test accuracy 1.25000\n","batch 5 -- Test loss 0.16551, Test accuracy 1.04167\n","batch 6 -- Test loss 0.16555, Test accuracy 0.89286\n","batch 7 -- Test loss 0.16559, Test accuracy 0.78125\n","batch 8 -- Test loss 0.16561, Test accuracy 0.69444\n","batch 9 -- Test loss 0.16564, Test accuracy 0.62500\n","batch 10 -- Test loss 0.16565, Test accuracy 0.56818\n","batch 11 -- Test loss 0.16567, Test accuracy 0.52083\n","batch 12 -- Test loss 0.16568, Test accuracy 0.48077\n","batch 13 -- Test loss 0.16569, Test accuracy 0.44643\n","batch 14 -- Test loss 0.16570, Test accuracy 0.41667\n","batch 15 -- Test loss 0.16571, Test accuracy 0.39062\n","batch 16 -- Test loss 0.16572, Test accuracy 0.36765\n","batch 17 -- Test loss 0.16572, Test accuracy 0.34722\n","batch 18 -- Test loss 0.16573, Test accuracy 0.32895\n","batch 19 -- Test loss 0.16573, Test accuracy 0.31250\n","batch 20 -- Test loss 0.16571, Test accuracy 0.44643\n","batch 21 -- Test loss 0.16572, Test accuracy 0.42614\n","batch 22 -- Test loss 0.16572, Test accuracy 0.40761\n","batch 23 -- Test loss 0.16573, Test accuracy 0.39062\n","batch 24 -- Test loss 0.16573, Test accuracy 0.37500\n","batch 25 -- Test loss 0.16574, Test accuracy 0.36058\n","batch 26 -- Test loss 0.16574, Test accuracy 0.34722\n","batch 27 -- Test loss 0.16574, Test accuracy 0.33482\n","batch 28 -- Test loss 0.16575, Test accuracy 0.32328\n","batch 29 -- Test loss 0.16575, Test accuracy 0.31250\n","batch 30 -- Test loss 0.16573, Test accuracy 0.40323\n","batch 31 -- Test loss 0.16573, Test accuracy 0.39062\n","batch 32 -- Test loss 0.16574, Test accuracy 0.37879\n","batch 33 -- Test loss 0.16574, Test accuracy 0.36765\n","batch 34 -- Test loss 0.16574, Test accuracy 0.35714\n","batch 35 -- Test loss 0.16574, Test accuracy 0.34722\n","batch 36 -- Test loss 0.16575, Test accuracy 0.33784\n","batch 37 -- Test loss 0.16575, Test accuracy 0.32895\n","batch 38 -- Test loss 0.16575, Test accuracy 0.32051\n","batch 39 -- Test loss 0.16575, Test accuracy 0.31250\n","batch 40 -- Test loss 0.16576, Test accuracy 0.30488\n","batch 41 -- Test loss 0.16576, Test accuracy 0.29762\n","batch 42 -- Test loss 0.16576, Test accuracy 0.29070\n","batch 43 -- Test loss 0.16576, Test accuracy 0.28409\n","batch 44 -- Test loss 0.16576, Test accuracy 0.27778\n","batch 45 -- Test loss 0.16576, Test accuracy 0.27174\n","batch 46 -- Test loss 0.16576, Test accuracy 0.26596\n","batch 47 -- Test loss 0.16577, Test accuracy 0.26042\n","batch 48 -- Test loss 0.16577, Test accuracy 0.25510\n","batch 49 -- Test loss 0.16577, Test accuracy 0.25000\n","batch 50 -- Test loss 0.16577, Test accuracy 0.24510\n","batch 51 -- Test loss 0.16577, Test accuracy 0.24038\n","batch 52 -- Test loss 0.16577, Test accuracy 0.23585\n","batch 53 -- Test loss 0.16577, Test accuracy 0.23148\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet_MEMO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[19], line 30\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(run_name, batch_size, device, learning_rate, weight_decay, momentum, num_augmentations)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# initialize the cost function\u001b[39;00m\n\u001b[1;32m     28\u001b[0m cost_function \u001b[38;5;241m=\u001b[39m get_cost_function()\n\u001b[0;32m---> 30\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, data_loader, B, cost_function, optimizer, transforms, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m intermediate_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m---> 25\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43mttr_MEMO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m   intermediate_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(intermediate_outputs)\u001b[38;5;241m.\u001b[39mto(device)\n","Cell \u001b[0;32mIn[17], line 13\u001b[0m, in \u001b[0;36mttr_MEMO\u001b[0;34m(model, test_sample, labels, B, cost_function, optimizer, transforms, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m augmented_images \u001b[38;5;241m=\u001b[39m augment_image(test_sample, augmentations, B)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# get the marginal output distribution\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m marginal_dist \u001b[38;5;241m=\u001b[39m \u001b[43mmarginal_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# update the model weights\u001b[39;00m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m marginal_cross_entropy(marginal_dist, labels, cost_function)\n","Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mmarginal_distribution\u001b[0;34m(images, model, transforms, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m      6\u001b[0m   single_batch \u001b[38;5;241m=\u001b[39m transforms(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m   prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)[indices_in_1k]\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m   img_results\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# sum all the resulting tensors\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torchvision/models/resnet.py:154\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m--> 154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["main(\"resnet_MEMO\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
