{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# DL Project 2023/24"],"metadata":{"id":"PDYnDRjPfNF_"}},{"cell_type":"markdown","source":["## Introduction\n","\n","Description of the method choosen and the work done"],"metadata":{"id":"ll5uAwzhfYHn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lw7k2mxRfE1D"},"outputs":[],"source":["# import modules\n","import torch\n","import torchvision\n","from torchvision.models import resnet50, ResNet50_Weights\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQnIh3lo3VAS","executionInfo":{"status":"ok","timestamp":1715856424792,"user_tz":-120,"elapsed":20847,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"}},"outputId":"66bcb2fb-5723-4a27-9d16-d142ff636adf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Reading Data"],"metadata":{"id":"MqX-jwMHgZ3G"}},{"cell_type":"code","source":["import tarfile\n","import os\n","import shutil\n","import re\n","\n","tar_file = \"./drive/MyDrive/DL_project/imagenet-a.tar\"\n","data_folder = \"imagenet-a\"\n","\n","# function to untar the dataset and store it in a new folder\n","def extract_dataset(compress_file, destination_folder):\n","  # function to change dir names to their words description\n","  def change_folders_names(readme_file, dataset_root):\n","    with open(readme_file, 'r') as f:\n","        lines = f.readlines()\n","        for line in lines:\n","            # Match lines containing WordNet IDs and descriptions\n","            match = re.match(r'n\\d+ (.+)', line)\n","            if match:\n","                # Split the line into WordNet ID and description\n","                parts = match.group(0).split()\n","                wordnet_id = parts[0]\n","                description = ' '.join(parts[1:])\n","                os.rename(os.path.join(dataset_root, wordnet_id),\n","                            os.path.join(dataset_root, description))\n","\n","  if not os.path.exists(compress_file):\n","    print(\"Compress file doesn't exist.\")\n","    return\n","\n","  if os.path.exists(destination_folder):\n","    # remove the folder if already exists one\n","    shutil.rmtree(destination_folder)\n","\n","  # extract content from the .tar file\n","  with tarfile.open(compress_file, 'r') as tar_ref:\n","    tar_ref.extractall(\"./\")\n","  print(\"All the data is extracted.\")\n","\n","  change_folders_names(destination_folder+\"/README.txt\", destination_folder)\n","\n","extract_dataset(tar_file, data_folder)"],"metadata":{"id":"4h7Y7SSrgc7y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715856438035,"user_tz":-120,"elapsed":10899,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"}},"outputId":"1081ee9c-4ae9-427b-dc24-b9658c11d5df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All the data is extracted.\n"]}]},{"cell_type":"code","source":["ids_list = os.listdir(data_folder)\n","print(ids_list)\n","len(ids_list) # 200 folders + 1 readme"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzBAWU06L_Mm","executionInfo":{"status":"ok","timestamp":1715856475223,"user_tz":-120,"elapsed":285,"user":{"displayName":"Edoardo Cecchinato","userId":"16439300506635722937"}},"outputId":"6bdd113a-71c9-4926-e3a5-ff9fac1fb7d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['African bush elephant', 'bikini', 'fox squirrel', 'broccoli', 'go-kart', 'bald eagle', 'hot dog', 'Persian cat', 'porcupine', 'balloon', 'mushroom', 'cello', 'cliff', 'lighter', 'Chihuahua', 'barn', 'README.txt', 'hair dryer', 'schooner', 'water tower', 'washing machine', 'forklift', 'gossamer-winged butterfly', 'castle', 'bow', 'submarine', 'maraca', 'accordion', 'bell pepper', 'revolver', 'snail', 'bubble', 'harvestman', 'centipede', 'cockroach', 'chest', 'custard apple', 'mantis', 'beaker', 'chain', 'canoe', 'weevil', 'box turtle', 'dragonfly', 'Christmas stocking', 'rugby ball', 'stingray', 'toaster', 'manhole cover', 'steam locomotive', 'goblet', 'jeep', 'dumbbell', 'pelican', 'cradle', 'garbage truck', 'organ', 'red fox', 'tarantula', 'reel', 'mask', 'Golden Retriever', 'agama', 'lighthouse', 'pomegranate', 'stick insect', 'quill', 'torch', 'kimono', 'suspension bridge', 'airliner', 'nail', 'marimba', 'Rottweiler', 'hockey puck', 'digital clock', 'unicycle', 'ocarina', 'envelope', 'drumstick', 'leafhopper', \"jack-o'-lantern\", 'small white', 'American black bear', 'bison', 'sandal', 'breastplate', 'cowboy boot', 'lynx', 'goldfinch', 'wheelbarrow', 'goose', 'academic gown', 'carbonara', 'koala', 'mitten', 'hermit crab', 'fly', 'ambulance', 'syringe', 'cheeseburger', 'sleeping bag', 'great egret', 'lorikeet', 'racket', 'golf cart', 'green iguana', 'flatworm', 'flamingo', 'mongoose', 'acorn', 'grand piano', 'teddy bear', 'rhinoceros beetle', 'rapeseed', 'rotary dial telephone', 'balance beam', 'cucumber', 'flagpole', 'volcano', 'basketball', 'newt', 'baseball player', 'sewing machine', 'sea lion', 'chameleon', 'lemon', 'sundial', 'spider web', \"yellow lady's slipper\", 'doormat', 'sea anemone', 'sulphur-crested cockatoo', 'billiard table', 'parachute', 'piggy bank', 'obelisk', 'snowmobile', 'tricycle', 'clothes iron', 'ant', 'vulture', 'salt shaker', 'American alligator', 'broom', 'couch', 'German Shepherd Dog', 'bow tie', 'jay', 'toucan', 'pretzel', 'feather boa', 'pufferfish', 'duck', 'fountain', 'banjo', 'candle', 'cottontail rabbit', 'volleyball', 'shovel', 'tank', 'wine bottle', 'soap dispenser', 'jellyfish', 'school bus', 'grasshopper', 'lion', 'spatula', 'crayfish', 'American bullfrog', 'umbrella', 'acoustic guitar', 'American robin', 'stethoscope', 'bee', 'ladybug', 'baboon', 'apron', 'shipwreck', 'marmot', 'scorpion', 'armadillo', 'guacamole', 'oystercatcher', 'monarch butterfly', 'parking meter', 'white-headed capuchin', 'viaduct', 'skunk', 'rocking chair', 'starfish', 'saxophone', 'mosque', 'banana', 'junco', 'garter snake', 'hummingbird', 'limousine', 'snowplow', 'pug', 'corn']\n"]},{"output_type":"execute_result","data":{"text/plain":["201"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from PIL import Image\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","\n","# function that returns a DataLoader for the dataset\n","def get_data(batch_size, dataset_path, transform):\n","\n","  data = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n","\n","  class_labels = data.classes\n","  print(f\"The dataset contains {len(data)} images.\")\n","  print(f\"The dataset contains {len(class_labels)} labels.\")\n","\n","  test_loader = torch.utils.data.DataLoader(data, batch_size, shuffle=False, num_workers=8)\n","\n","  return test_loader, class_labels"],"metadata":{"id":"eul04CxP3VaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torchvision.transforms.functional as TF\n","\n","# function to display images from the DataLoader\n","def show_images(dataloader, num_images=5):\n","  # get a batch of data\n","  data_iter = iter(dataloader)\n","  images, labels = next(data_iter)\n","\n","  # convert images to numpy array\n","  images = images.numpy()\n","\n","  # display images\n","  fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n","  for i in range(num_images):\n","      image = np.transpose(images[i], (1, 2, 0))  # move channels in last position\n","      image = np.clip(image, 0, 1)\n","      axes[i].imshow(image)\n","      axes[i].axis('off')\n","      axes[i].set_title(dataloader.dataset.classes[labels[i]])\n","  plt.show()"],"metadata":{"id":"HHAElKCP7mMv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MEMO"],"metadata":{"id":"VxlU46PFgdSd"}},{"cell_type":"code","source":["from PIL import ImageOps, ImageEnhance\n","\n","# define some image augmentations\n","\n","def vertical_flip(img):\n","    img = TF.to_pil_image(img)\n","    res = img.transpose(Image.FLIP_TOP_BOTTOM)\n","    return TF.to_tensor(res)\n","\n","def brightness(img, factor_range=(0.5, 1.5)):\n","  img = TF.to_pil_image(img)\n","  factor = np.random.uniform(factor_range[0], factor_range[1])\n","  enhancer = ImageEnhance.Brightness(img)\n","  res = enhancer.enhance(factor)\n","  return TF.to_tensor(res)\n","\n","'''\n","def rotation(img, angle_range=(-45, 45)):\n","  angle = np.random.uniform(angle_range[0], angle_range[1])\n","  return img.rotate(angle)\n","'''\n","\n","def color(img, factor_range=(0.5, 1.5)):\n","  img = TF.to_pil_image(img)\n","  factor = np.random.uniform(factor_range[0], factor_range[1])\n","  enhancer = ImageEnhance.Color(img)\n","  res = enhancer.enhance(factor)\n","  return TF.to_tensor(res)\n","\n","def sharpness(img, factor_range=(0.5, 1.5)):\n","  img = TF.to_pil_image(img)\n","  factor = np.random.uniform(factor_range[0], factor_range[1])\n","  enhancer = ImageEnhance.Sharpness(img)\n","  res = enhancer.enhance(factor)\n","  return TF.to_tensor(res)\n","\n","augmentations = [vertical_flip, brightness, color, sharpness]"],"metadata":{"id":"tNxMhrlyj5IW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","# functon that apply B augmentations to the original image and return M+1 images\n","def augment_image(img, augmentations, B=15):\n","  assert len(augmentations) > 0, \"There are not augmentations provided.\"\n","\n","  images = [img]\n","  for _ in range(B):\n","    # randomly choose an augmentation in the augmentation functions\n","    index = random.randrange(0, len(augmentations))\n","    augmentation = augmentations[index]\n","    # apply the augmentation to the original image\n","    augmented_img = augmentation(img)\n","    # add the augmented image to the list of images I want to evaluate\n","    images.append(augmented_img)\n","  return images"],"metadata":{"id":"9WXWL3Gxh3Cr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the cost function used to evaluate the model output\n","def get_cost_function():\n","  cost_function = torch.nn.CrossEntropyLoss()\n","  return cost_function"],"metadata":{"id":"xc5j-FiVdoBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the optimizer\n","def get_optimizer(net, lr, wd, momentum):\n","    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n","    return optimizer"],"metadata":{"id":"pxiafvsgPisv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute the marginal output distribution\n","def marginal_distribution(images, model, transforms, device):\n","  # collect the prediction for every image in input\n","  img_results = []\n","  for img in images:\n","    single_batch = transforms(img).unsqueeze(0).to(device)\n","    prediction = model(single_batch).squeeze(0).softmax(0)\n","    img_results.append(prediction)\n","\n","  # sum all the resulting tensors\n","  sum_results = torch.sum(torch.stack(img_results), dim=0).to(device)\n","  # divide each element by B to obtain the marginal output distribution\n","  num_images = len(images)\n","  res = torch.div(sum_results, num_images).to(device)\n","  return res"],"metadata":{"id":"bhN-AaM_huqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy\n","\n","# test time robustness via MEMO algorithm\n","def ttr_MEMO(model, test_sample, label, B, cost_function, optimizer, transforms, device):\n","  # save the original model weights\n","  original_params = copy.deepcopy(model.state_dict())\n","\n","  with torch.enable_grad():\n","    # get the B + 1 images\n","    augmented_images = augment_image(test_sample, augmentations, B)\n","\n","    # get the marginal output distribution\n","    marginal_dist = marginal_distribution(augmented_images, model, transforms, device)\n","\n","    # update the model weights\n","    loss = cost_function(marginal_dist, label)\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","  test_sample = transforms(test_sample).unsqueeze(0).to(device)\n","  output = model(test_sample).squeeze(0).softmax(0)\n","\n","  # reapply original weights to the model\n","  model.load_state_dict(original_params)\n","\n","  return output"],"metadata":{"id":"_cmtwAFRFCoW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test Procedure"],"metadata":{"id":"98wdJeghGZsv"}},{"cell_type":"code","source":["def test(model, data_loader, B, cost_function, optimizer, transforms, device=\"cuda\"):\n","  samples = 0.0\n","  cumulative_loss = 0.0\n","  cumulative_accuracy = 0.0\n","\n","  # set the network to evaluation mode\n","  model.eval()\n","\n","  # disable gradient computation for testing mode\n","  with torch.no_grad():\n","    # iterate over the test set\n","    for batch_idx, (inputs, targets) in enumerate(data_loader):\n","      # Load data into GPU\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      # forward pass\n","      batch_size = inputs.size(0)\n","      num_labels = 1000 # 1000 is the ImageNet number of labels\n","      empty_tensor = torch.empty(num_labels).to(device)\n","\n","      # apply MEMO to each test point in the batch\n","      intermediate_outputs = []\n","      for input, target in zip(inputs, targets):\n","        output = ttr_MEMO(model, input, target, B, cost_function, optimizer, transforms, device)\n","        intermediate_outputs.append(output)\n","\n","      outputs = torch.stack(intermediate_outputs).to(device)\n","\n","      # outputs_no_MEMO = model(inputs)\n","\n","      # loss computation\n","      loss = cost_function(outputs, targets)\n","\n","      # fetch prediction and loss value\n","      samples+=inputs.shape[0]\n","      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n","      _, predicted = outputs.max(1)\n","\n","      # compute accuracy\n","      cumulative_accuracy += predicted.eq(targets).sum().item()\n","\n","  return cumulative_loss / samples, cumulative_accuracy / samples * 100"],"metadata":{"id":"BXSBVg2bGdlZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Put all together"],"metadata":{"id":"-mjNvK8WYlEk"}},{"cell_type":"code","source":["def main(\n","    run_name,\n","    batch_size = 32,\n","    device = \"cuda\",\n","    learning_rate=0.001,\n","    weight_decay=0.000001,\n","    momentum=0.9,\n","    num_augmentations = 15\n","):\n","  # writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n","  device = device\n","\n","  # itialize the ResNet model\n","  weights = ResNet50_Weights.DEFAULT\n","  model = resnet50(weights=weights).to(device)\n","\n","  # initialize the inference transforms\n","  preprocess = weights.transforms()\n","  preprocess\n","\n","  # initialize the test dataloader\n","  test_loader, _ = get_data(batch_size, data_folder, preprocess)\n","\n","  # initialize the optimizer\n","  optimizer = get_optimizer(model, learning_rate, weight_decay, momentum)\n","\n","  # initialize the cost function\n","  cost_function = get_cost_function()\n","\n","  test_loss, test_accuracy = test(model, test_loader, num_augmentations, cost_function, optimizer, preprocess, device)\n","  print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")"],"metadata":{"id":"GWwZuurhYpza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main(\"resnet_MEMO\")"],"metadata":{"id":"lCWTd6ZxHqiE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3319351-f576-4e9f-ce97-430988aa52f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset contains 7500 images.\n","The dataset contains 200 labels.\n"]}]}]}